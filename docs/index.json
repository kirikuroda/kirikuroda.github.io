[{"authors":["admin"],"categories":null,"content":"黒田起吏は、東京大学で社会心理学を専攻する大学院生である。彼は、行動実験・アイトラッキング・認知モデリングを用いながら、ヒトの集団意思決定を研究している。\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"ja","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://kirikuroda.github.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"黒田起吏は、東京大学で社会心理学を専攻する大学院生である。彼","tags":null,"title":"Kiri Kuroda","type":"authors"},{"authors":null,"categories":["実験"],"content":"  はじめに 背景 このページの概要  遅延割引のモデルを解説 遅延割引課題とは 遅延割引のモデル 2肢選択のモデル  実際に遅延割引パラメタを推定する 実験データを作ってみる 素朴にパラメタを推定してみる 尤度を計算する 対数尤度を計算する optimでパラメタを推定する  おわりに   はじめに 背景 いま一部の心理学領域で、認知モデルを立ててそのパラメタを推定する、あるいは、複数のモデルの良さを比較する、というデータ分析がスタンダードになりつつあります。また、その分析手法として、主にStanを使ったベイズ推定が取り上げられるようになっています。\nしかし、一体どれだけの人（特に学部生）がベイズ推定についていけているでしょうか？　実際には、「ベイズ推定どころか最尤推定って何？　具体的にはどう計算するの？　どういうコードを書けばいいの？　そもそも認知モデルって何？」となってしまう1場合が多いのでは？、というのが私の肌感覚です。\nそういう「置いてけぼり感」を覚えてしまうことに無理はないです。現状、心理学（特に社会心理学）の授業で、認知モデルに関するトレーニングを受ける機会は少ないからです2。\n\n このページの概要 そこでこのページでは、遅延割引課題を例として、認知モデルのパラメタをどうやって最尤推定するかを、具体的に見ていくことにします。推定にはRを使います。\nなお、この課題については、『社会科学のためのベイズ統計モデリング』の第9章を参考にしています。より詳しく知りたい方は、そちらを読んでください。\n\n  遅延割引のモデルを解説 遅延割引課題とは 遅延割引課題とは、「いますぐに小さい金額をもらうか、だいぶ先になっちゃうけどより大きい金額をもらうか」のどちらかを選ぶという課題です。\nここでは、「いますぐにr円をもらうか、n日後に50000円をもらうか」のどちらかを選ぶことになったとします。もっと具体的に考えるために、以下の2つの例を考えてみましょう。\nまず、「いますぐに5000円をもらうか、30日後に50000円をもらうか」と聞かれたら、どっちを選びますか？　おそらく、多くの人は「30日後に50000円」を選ぶのではないでしょうか。\n次に、「いますぐに45000円をもらうか、720日後に50000円をもらうか」と聞かれたら、どっちを選びますか？　ここでは逆に、「いますぐに45000円」を選ぶ人が多いと思います。\nイメージはつきましたか？　この例からわかるように、遅延割引課題は「長期的利益のために、人々が目先の利益をどれくらい我慢できるか」を測定するものです。\n\n 遅延割引のモデル さて、「人が長期的な利益をどれくらい良いと感じるか」は、以下の式（モデル）で表現できるとされています3：\n\\[ U(A,t) = U(A)\\frac{1}{1+kt} \\]\nそれぞれの記号は以下の内容を表しています：\n \\(A\\)：金額。ここでは50000円だと考えてください\n \\(t\\)：何日後に\\(A\\)（すなわち50000円）をもらえるか\n \\(U(A, t)\\)：\\(t\\)日後に\\(A\\)（50000円）をもらった場合の「嬉しさ」4\n \\(U(A)\\)：いますぐに\\(A\\)（50000円）をもらった場合の嬉しさ\n \\(k\\)：遅延割引パラメタ\n  \nでは、この\\(k\\)（遅延割引パラメタ）とは具体的にどういうものなのでしょうか？　それを理解するために、\\(k\\)をいじってみましょう。\n下の図の横軸は「t日」、縦軸は「そのとき50000円をもらったときの嬉しさ（すなわち、\\(U(A,t)\\)）」を表しています。ここでは、\\(t\\)日を0〜30で変化させ、\\(k\\)を0から0.5まで0.05刻みで変化させています。\nこの図からどういうことが読み取れるでしょうか？\nlibrary(tidyverse) expand_grid(t = 0:30, k = seq(0, 0.5, 0.05)) %\u0026gt;% mutate(u = 50000 * (1 / (1 + k * t))) %\u0026gt;% ggplot(aes(x = t, y = u, group = k, color = k)) + geom_line() + scale_color_viridis_c() + labs(x = \u0026quot;t（日）\u0026quot;, y = \u0026quot;t日後に50000円もらったときの嬉しさ\u0026quot;) + theme_minimal(base_family = \u0026quot;ヒラギノ角ゴシック W3\u0026quot;) + theme(axis.text = element_text(color = \u0026quot;#333333\u0026quot;))  Figure 1: 図1. t日後に50000円もらったときの嬉しさ  \nまず、\\(t = 0\\)のとき、\\(k\\)がどんな値であれ、縦軸（50000円もらったときの嬉しさ）は50000円です。\\(t = 0\\)は「今すぐ」と同じだからです。\n次に、\\(t\\)が大きくなるほど、「\\(t\\)日後に50000円」の嬉しさは低くなっていることがわかります。\nまた、\\(k\\)が大きくなるほど（線が明るい色になるほど）、「\\(t\\)日後に50000円」の嬉しさは低くなっています。これを引っ張って考えると、「\\(k\\)が大きい人ほど、今すぐの利益に目がくらんでしまいがち」ということになります5。\n\n 2肢選択のモデル では次に「2つの選択肢（目先の利益 vs. 長期的な利益）をどうやって選ぶか」のモデルを考えてみましょう。\nここでは「今すぐ5000円をもらうか、1ヶ月後に50000円をもらうか」を選ぶ状況を例としてみます。私たちは多くの場合、「1ヶ月後に50000円」を選ぶでしょう。\nしかし、人間というものは、そこまで完璧ではありません。もし「ねえ、今すぐ5000円あげるけど、欲しいよね？」と100回も聞かれたら、何回かは誘惑にかられて「今すぐ5000円」を選んでしまうかもしれません。\nこのような現象を表すため、よくロジスティック関数6というものが用いられます。遅延割引課題の例では、以下のように書くことができます。\n\\[ P_{d} = \\frac{1}{1+\\exp(-\\beta[U(A^{d})-U(A^{s})])} \\]\n記号の意味は以下のとおりです。\n \\(P_{d}\\)：遅延報酬（\\(t\\)日後に50000円）を選ぶ確率（0〜1の値）\n \\(U(A^{d})\\)：遅延報酬をもらった時の嬉しさ\n \\(U(A^{s})\\)：即時報酬（今すぐの報酬）をもらった時の嬉しさ\n \\(\\beta\\)：逆温度パラメタ（嬉しさの差分にどれくらい敏感に反応するか）\n  \n詳しくは「ロジスティック関数」などで調べてほしいのですが、この式で大事なのは以下の2点です。\n\\(U(A^{d})-U(A^{s})\\)が大きくなるほど\\(P_{d}\\)も大きくなる。すなわち、遅延報酬が即時報酬よりも魅力的であるほど、遅延報酬を選ぶ確率が高くなるということです。裏を返すと、即時報酬のほうが魅力的であるほど、遅延報酬を選ぶ確率が低くなる（つまり、即時報酬を選ぶ確率が高くなる）ということも表しています。\n \\(\\beta\\)が大きいほど、「嬉しさ」の差分に強く反応する。つまり、\\(\\beta\\)が大きい場合、嬉しさの大きい方を忠実に選ぶようになるということです。逆に\\(\\beta\\)が0に近いほど、どちらを選ぶかはランダムに近づく（「誘惑に駆られやすくなる」）ということも表しています。\n  \n\nさて、遅延割引課題を用いた研究で知りたいのは、ある人（参加者）がどれくらい目先の利益に目がくらみがちか、そして、ある人（参加者）がどれくらい「嬉しさ」の差分に強く反応するかということです。これを言い換えると、ある人がどれくらいの\\(k\\)（遅延割引パラメタ）を持っているか、ある人がどれくらいの\\(\\beta\\)（逆温度パラメタ）を持っているかということになります。\n認知モデルのパラメタを推定するというのは、まさに「ある人がどれくらいのパラメタ（認知的な傾向）を持っているか」を探ろうとする分析を意味しています。\n\n  実際に遅延割引パラメタを推定する 実験データを作ってみる ここで具体的な分析方法を説明したいのですが、まだ手元にはデータがありません。\nそこで、ある1人の参加者が50回の遅延割引課題に取り組んだと仮定します。具体的には「\\(t\\)日後に50000円をもらうか、今すぐ\\(r\\)円をもらうか」を選んだとしましょう。各回で、日数\\(t\\)は｛30, 90, 180, 360, 720｝のいずれか、今すぐの報酬\\(r\\)は｛5000, 1000, …, 50000｝のいずれかとします（5通り×10通りなので50回の課題、ということです）。では、下のコードのように仮想的なデータを作り、dataというデータフレームとして保存してみましょう7。\nset.seed(1) data \u0026lt;- expand_grid( t = c(30, 90, 180, 360, 720), r = seq(5000, 50000, 5000) ) %\u0026gt;% mutate( u_delay = 50000 * (1 / (1 + 0.01 * t)), p = 1 / (1 + exp(-0.00005 * (u_delay - r))) ) %\u0026gt;% group_by(row_number()) %\u0026gt;% mutate(choice = rbinom(1, 1, p)) \nでは、この参加者は遅延報酬（「\\(t\\)日後に50000円」）を何回選んだのでしょうか？　遅延報酬を選んだ場合、dataのchoiceという変数は1になっています。逆に即時報酬（「すぐに\\(r\\)円」）を選んだ場合、choiceは0です。\n参加者の選択を下にプロットしてみました。横軸は遅延日数\\(t\\)、縦軸は選択（0か1）、各パネルの上の数字は即時報酬の金額を表しています。\ndata %\u0026gt;% ggplot(aes(x = t, y = choice)) + geom_point() + scale_y_continuous(breaks = c(0, 1)) + facet_wrap(~r)  Figure 2: 図2．ある参加者がどれくらい遅延報酬を選んだか  \n 素朴にパラメタを推定してみる さて、どのようにパラメタを推定すればよいのでしょうか？　まず、素朴なアイデアから出発してみます。\nたとえば、「なんとなくだけど、\\(k\\)は0.1で、\\(\\beta\\)は0.0001じゃね？」と考えたとしましょう。このとき、これらのパラメタの値はどれくらいふさわしいでしょうか？　また、そのふさわしさはどのように評価（計算）されるべきでしょうか？\nとりあえず、上で説明した2つのモデルに代入してみましょう。ここでは、「今すぐ5000円」と「30日後に50000円」を比べた場合を考えてみます。\nt \u0026lt;- 30 k \u0026lt;- 0.1 beta \u0026lt;- 0.0001 # u_delay：遅延報酬のU u_delay \u0026lt;- 50000 * (1 / (1 + 0.1 * t)) # 30日後に50000円を選ぶ確率 p \u0026lt;- 1 / (1 + exp(-beta * (u_delay - 5000))) print(p) ## [1] 0.6791787 \nさて、\\(k = 0.1\\)、\\(\\beta = 0.0001\\)としたとき、遅延報酬を選ぶ確率は0.6791787になりました。では、実際のデータはどうだったでしょうか？（つまり、「今すぐ5000円 vs. 30日後に50000円」のとき、どっちを選んでいたでしょうか？）\n図2を見ると、参加者は遅延報酬（30日後に50000円）を選んでいたことがわかります。では、上の計算で出てきた「遅延報酬を選ぶ確率は0.6791787」と「参加者が実際に遅延報酬を選んでいたという事実」はどのように関係しているのでしょうか。\n「遅延報酬を選ぶ確率」というのは、「『遅延報酬を選ぶ』という結果が得られる確率」と言い換えることができます。この「『遅延報酬を選ぶ』という結果が得られる確率」は、パラメタ\\(k\\)と\\(\\beta\\)を色々な値にすれば、それに応じて様々な値に変動します。\nここで、「参加者が実際に遅延報酬を選んで」いたとしましょう。このとき、適当にパラメタを代入して、「『遅延報酬を選ぶ』という結果が得られる確率」が高かった場合、それは何を意味しているでしょうか。\n日常言語で表すと、「参加者は遅延報酬を選んだ。適当にパラメタを代入したら、遅延報酬を選ぶ確率は高いらしい。これって結構近いじゃん」ということになります。さらにこれを引っ張ると、「予結構近いんだから、このパラメタって、もしかして良い線行ってるんじゃね？」となります。逆に、予測が外れた場合は、そのパラメタはあまりよろしくないと言えます。\nつまり、「ある結果が得られている。そこで、適当にパラメタを設定したら、その結果が得られる確率も高いようだ。だったら、そのパラメタは『ふさわしい』んじゃないか」ということです。このようなパラメタの「ふさわしさ」（パラメタを設定したとき、手元のデータが得られる確率）を真面目に言うと「尤度」になります。また、尤度をもとにパラメタを推定する方法を最尤推定と言います。\nこの例では、「いま、参加者が遅延報酬を選んだことがわかっている。そこで、\\(k = 0.1\\)、\\(\\beta = 0.0001\\)としたとき、遅延報酬を選ぶ確率は0.6791787だった」となります。すなわち、尤度は0.6791787です8。\n\n 尤度を計算する では、\\(k = 0.1\\)、\\(\\beta = 0.0001\\)とし、全50回の尤度を計算してみましょう。まず、以下のコードを実行します。\nt \u0026lt;- 30 k \u0026lt;- 0.1 beta \u0026lt;- 0.0001 data %\u0026gt;% # 遅延報酬のUと、遅延報酬を選ぶ確率pを計算 mutate( u_delay = 50000 * (1 / (1 + k * t)), p = 1 / (1 + exp(-beta * (u_delay - r))) ) %\u0026gt;% # 遅延報酬を選ぶ確率pを抽出 pull(p) ## [1] 0.679178699 0.562176501 0.437823499 0.320821301 0.222700139 0.148047198 ## [7] 0.095349465 0.060086650 0.037326887 0.022977370 0.500000000 0.377540669 ## [13] 0.268941421 0.182425524 0.119202922 0.075858180 0.047425873 0.029312231 ## [19] 0.017986210 0.010986943 0.441064710 0.323695074 0.224986141 0.149714490 ## [25] 0.096490497 0.060834074 0.037802587 0.023274618 0.014247244 0.008690106 ## [31] 0.409782432 0.296323939 0.203450772 0.134137019 0.085891464 0.053918000 ## [37] 0.033411753 0.020535219 0.012556698 0.007653837 0.393766567 0.282619107 ## [43] 0.192864008 0.126583888 0.080801479 0.050617863 0.031325176 0.019236783 ## [49] 0.011756686 0.007163930 \n上に表示されているのは、遅延報酬を選ぶ確率\\(p\\)です。\nしかし、これをそのまま最尤推定に使うことはできません。なぜなら、尤度とは「あるパラメタを設定したときに、手元のデータが得られる確率」だからです。実験では、参加者が即時報酬を選ぶ場合も当然あるので、その場合は「即時報酬を選ぶ確率」を使わないといけません。したがって、各回の尤度（likelihood）は以下のようになります。\nlikelihood \u0026lt;- data %\u0026gt;% # 遅延報酬のUと、遅延報酬を選ぶ確率pを計算 # さらに、参加者の選択に応じて条件分岐をして尤度を計算 mutate( u_delay = 50000 * (1 / (1 + k * t)), p = 1 / (1 + exp(-beta * (u_delay - r))), likelihood = if_else(choice == 1, p, 1 - p) ) %\u0026gt;% pull(likelihood) likelihood ## [1] 0.67917870 0.56217650 0.43782350 0.67917870 0.22270014 0.85195280 ## [7] 0.90465054 0.06008665 0.03732689 0.97702263 0.50000000 0.37754067 ## [13] 0.73105858 0.18242552 0.88079708 0.92414182 0.04742587 0.02931223 ## [19] 0.98201379 0.01098694 0.55893529 0.32369507 0.77501386 0.85028551 ## [25] 0.90350950 0.93916593 0.96219741 0.97672538 0.01424724 0.99130989 ## [31] 0.40978243 0.70367606 0.79654923 0.86586298 0.08589146 0.94608200 ## [37] 0.03341175 0.97946478 0.98744330 0.99234616 0.60623343 0.28261911 ## [43] 0.19286401 0.87341611 0.91919852 0.05061786 0.96867482 0.98076322 ## [49] 0.98824331 0.99283607 \n 対数尤度を計算する では、ここで全50回の尤度を1つの指標にまとめたいと思います（まとめたいですよね？）。このとき、直観的には尤度を足し算すれば良いんじゃないか、と思うかもしれませんが、それは間違いです。\n正解は「かけ算」です。詳しい説明は適宜教科書を読むなり、ググってもらえるとありがたいです9。簡単な例で言えば、「3回連続でじゃんけんに勝つ確率は？」と聞かれたとき、「1/3を3回足して1」ではなく、「1/3を3回かけ算して1/27」と答えるのが正解になるのも同じ理屈です。\nでは、上で求めた尤度を全部かけ算してみましょう。\n# prod()で、要素を全部かけあわせることになる prod(likelihood) ## [1] 1.143327e-20 \nこれは0.000000000001067125を表しています。\nちっさ！って思うのではないでしょうか。と同時に、「やっぱ、パソコンはこんな細かい計算できて偉いなあ」と思う人がいるかもしれません。\nしかし、残念ながらそれは間違いです。あまりに数字が小さいと、パソコンの計算にも誤差が生じてしまいます10。\nこれを防ぐため、尤度を計算するときは、対数を取るというのが決まりになっています。なぜなら、かけ算の対数を取ると足し算になるという便利な性質があるからです11。対数を取って求めた尤度を「対数尤度（log likelihood）」と言います。\nまた、対数は単調増加関数なので、「尤度の積が大きい（もっともらしい）場合は、その対数も大きくなる」という関係が成り立ちます。対数、便利です。\nでは、対数尤度を計算し、全部を足し算してみましょう。\nsum(log(likelihood)) ## [1] -45.91776 \n確認のため、尤度を全部掛け算したやつの対数を取ってみましょう。\nlog(prod(likelihood)) ## [1] -45.91776 \nちゃんと2つが一致しました。ただし、データの数が多いほどかけ算の誤差は大きくなるので、やはり対数を取ってから足し算をするようにしましょう。\n\n optimでパラメタを推定する さて、\\(k = 0.1\\)、\\(\\beta = 0.0001\\)としたときの50回の対数尤度は-27.56605になりました。\nで？　それが何？\nそうです。これだけでは、まだ何も言えていません。他のパラメタの候補も調べないと、どのパラメタが良さそうかはわかりません。\nでは、どうすればよいでしょうか？　素朴に考えたら、有り得そうな\\(k\\)や\\(\\beta\\)を片っ端から代入して対数尤度を計算する、というのが良さそうです。しかし、そんな時間は私たちにはありません。\nそこで使うのが、Rの最適化関数optimです。最適化関数とは、ある関数の最大値／最小値を求めるための道具だと考えてください。\nいま私たちがやりたいのは、対数尤度が最も大きくなりそうなパラメタ\\(k\\)と\\(\\beta\\)の組み合わせを調べるということです。つまり、optimを使って、対数尤度（関数）が最大化されるような\\(k\\)と\\(\\beta\\)を見つければ目的達成ということになります。\nでは、具体的な書き方を説明します。まず、対数尤度関数（ll_delay）を自分で定義します。\n# 関数を定義する ll_delay \u0026lt;- function(param, data) { # param[1]はk、param[2]はbetaを表している # dataは参加者のデータフレームそのものを表している data %\u0026gt;% # 毎回の対数尤度を計算する mutate( u_delay = 50000 * (1 / (1 + param[1] * t)), p = 1 / (1 + exp(-param[2] * (u_delay - r))), likelihood = if_else(choice == 1, p, 1 - p), ll = log(likelihood) ) %\u0026gt;% # 最後に全部足し合わせる pull(ll) %\u0026gt;% sum() } \nこれをoptimに突っ込みます。parには推定したいパラメタの初期値、fnには最適化したい関数を入れます。control = list(fnscale = -1)とすると、関数の最大化が行われるようになります。その他の引数（この例ではdata）では、ll_delayにどんな引数を渡すかを指示してあげます。\noptim(par = c(0.1, 0.0001), fn = ll_delay, data = data, control = list(fnscale = -1)) ## $par ## [1] 0.0132120062 0.0000423154 ## ## $value ## [1] -30.70504 ## ## $counts ## function gradient ## 89 NA ## ## $convergence ## [1] 0 ## ## $message ## NULL \n結果のparが推定値を表しています。\\(k\\)が0.0132120062、\\(\\beta\\)は0.0000423154でした。\nでは、正解は何だったのでしょうか？　正解は、データを作ったコードの中に隠れています。改めてコードを見てみましょう。\nset.seed(1) data \u0026lt;- expand_grid( t = c(30, 90, 180, 360, 720), r = seq(5000, 50000, 5000) ) %\u0026gt;% mutate( u_delay = 50000 * (1 / (1 + 0.01 * t)), p = 1 / (1 + exp(-0.00005 * (u_delay - r))) ) %\u0026gt;% group_by(row_number()) %\u0026gt;% mutate(choice = rbinom(1, 1, p)) \n最初は詳しく説明しませんでしたが、このコードでは、遅延割引と2肢選択のモデルを用いて、参加者の選択を仮想的に作っていました。とくに7行目と8行目を見てください。ここでは、参加者が\\(k=0.01\\)、\\(\\beta=0.00005\\)というパラメタを持つように設定しています。さて、推定結果は\\(k=0.0132120062\\)、\\(\\beta=0.0000423154\\)でした。まあまあ良い線行ってるのではないでしょうか。\n\n  おわりに ここまで、駆け足で認知パラメタの最尤推定を見てきました。もちろん、まだまだ説明していないトピックはありますが、まずはここらへんの内容を押さえておくのが良いかと思います。\n\n  私が学部生の頃もそうでした。たとえば当時、とても偉い工学系の先生に「すみません、単回帰分析の最尤推定ってどうやるんですか？」みたいなことを聞いてたレベルです。ちなみに、単回帰分析の最尤推定は心理統計の教科書に載っているし、ググればすぐに出てくるような内容です。今思えばガチで恥ずかしいですが、「知らぬは一時の恥、聞かぬは一生の恥」です。そんな質問をしていた私ですら、いま一応なんとか生きてます。（以下、かなり脱線します。）わからないことがあったときにおすすめなのは、研究室や学科の先輩に質問することです。もちろんググっても良いのですが、先輩たちも同様の難所を乗り越えている場合が多いので、同じ目線で答えてくれる可能性が高いです。ただし、自分がふだん研究室に行かなかったり、先輩と全然コミュニケーションを取ったりしていないのに、「卒論締切間際に自分が困ったときにだけ質問する」みたいな姿勢は、傍から見ていると「それは虫が良すぎじゃね？」という感じがします。「ふだんから細かく」質問する、世間話をしておく（※先輩の機嫌を取るということではないです）、ぐらいのことをやっておいたほうが、長期的には良いと思います。このトピックだけで記事1つ書けそうです。↩︎\n まあ、「授業が全てを教えてくれる」という期待・態度がそもそも間違っているという説はあります。結局のところ、研究スキルなんて、試行錯誤で無理くり獲得していくものなのかもしれません。↩︎\n この式は、双曲割引（hyperbolic discounting）と言います。↩︎\n \\(U\\)は「嬉しさ（Ureshisa）」の頭文字のUではなく、本当は「効用（Utility）」の頭文字を表しています。ここで「効用」とか書いちゃうと難しくなるので、「嬉しさ」にしています。↩︎\n ちょっとジャンプがあるかもしれませんが、わからなかった場合はゆっくり考えてみてください。日常的な例（？）でいうと、\\(k\\)が大きいほど、「健康診断のため1ヶ月後に3kg痩せるのは、今すぐに飴玉を1個食べるのと等しいと感じてしまう」ということです。このような人は「今すぐ飴玉2個あげるよ」と言われたら、飴玉2個を食べてしまう（目がくらんでしまう）ということになります。逆に\\(k\\)が小さいと、「1ヶ月後に3kg痩せるのは、今すぐ高級マカロン100個を食べるのと等しいと感じる」ということです。このような人は「今すぐマカロン1個あげるよ」と言われても、「そんな少ないマカロンをもらうぐらいなら、我慢して減量したほうがマシ」と返事をして、拒絶することになるでしょう。↩︎\n ソフトマックス関数といったほうが厳密かもしれません。詳しくは『社会科学のためのベイズ統計モデリング』を読んだり、「ソフトマックス関数　ロジスティック関数」でググったりしてみてください。↩︎\n とりあえずこのコードの意味を意味を理解する必要はないです。↩︎\n 正直、尤度や最尤推定については他にもっと優れた記事があると思うので、わからなければ適宜ググってもらえると嬉しいです。↩︎\n 「積事象」や「尤度」でググってみてください。↩︎\n これをアンダーフローと言います。たとえば、Rのコンソールに1e-1000とか打ってみて、どうなるかを見てみましょう。↩︎\n この説明は端折りますが、一応文系数学の範囲です。「尤度」でググると、この内容は必ず説明されているので、適宜調べてみてください。↩︎\n   ","date":1599264000,"expirydate":-62135596800,"kind":"page","lang":"ja","lastmod":1599264000,"objectID":"4ca25394831b4d5a39d6e255377371af","permalink":"https://kirikuroda.github.io/post/2020/09/05/mle-delay-discounting/","publishdate":"2020-09-05T00:00:00Z","relpermalink":"/post/2020/09/05/mle-delay-discounting/","section":"post","summary":"遅延割引課題を例として使います","tags":null,"title":"認知モデルのパラメタを最尤推定する","type":"post"},{"authors":[],"categories":["実験"],"content":"目次  はじめに  想定している読者層 既に公開されている優れたチュートリアル このチュートリアルの特色（？）   いきなりやってみるタイプのチュートリアル  いきなりセットアップ いきなり実験 実験の構造   解説  ダイアログボックスを呈示する（38–46行目） データファイルの名前を作る（52–67行目） クイズの項目を読み込む（69–70行目） 画面、マウス、キーボードを設定する（76–80行目） 都市名刺激を設定する（86–103行目） キーを設定する（105–112行目） 教示を定義する（114–121行目） Startボタンを定義する（123–129行目） その他のテキスト刺激や図形を定義する（131–157行目） ログファイルを設定する（163–164行目） 教示を呈示する（170–190行目） CSVファイルの1行目に変数名を書き込む（192–199行目） カーソルを消して課題を始める（205–215行目） 都市名を呈示（217–244行目） 開始時間を記録し、キーボードをリセット（246–251行目） 回答を待つ（253–318行目） フィードバックをし、各試行のデータを記録（320–338行目） 実験終了（344–355行目）   おわりに   はじめに 想定している読者層 このチュートリアルでは、以下のタイプの読者を想定しています：\n  実験プログラムを書かなきゃいけなくなった心理学（特に社会心理学）系の学部生\n  卒論で（いきなり1）心理学実験のプログラムを書かなくちゃいけなくなった人\n  Pythonの初心者本は一通り読んだけど、いざPsychoPyになるとよくわからない人\n  Coderのどこから手を着ければいいかわからない人\n  せっかくやるならBuilderじゃなくてCoderがいい、でもよくわからない、という人\n  CoderにDemosってやつがあるらしいけど、英語を読むことに苦手意識がある（あるいは、Demosの存在を知らない）という人\n  時間がない人\n  既に公開されている優れたチュートリアル PsychoPyのCoderについては、既に優れたチュートリアルがいくつか公開されています（参照： PsychoPy Coderによる心理学実験作成チュートリアルまとめ）。この「チュートリアルまとめ」、およびそこで紹介されているチュートリアルのいずれにおいても、Pythonの初歩から実験実施までが丁寧に解説されています。\nこのチュートリアルの特色（？） このチュートリアルでは、Pythonの初歩の説明をすっ飛ばします。上で紹介した記事も含め、もっと優れた資料や書籍が山のようにあるからです。\nその代わりに、（社会）心理学の実験で割と使うと思われる機能に絞って話を進めます。くわえてこのチュートリアルでは、最初から完成したコードを見て、それを順に解説していくという方針を取ります。「該当するコードをコピペしていけば、自分の実験も書けるんじゃないか？」と思ってもらえることを狙っています。\n主に説明するのは以下の機能です：\n ダイアログボックス データをCSVに記録 テキスト刺激の呈示 キー押しの検出 クリックの検出 反応時間の計測 マウスやキー押しに応じて刺激の色を変える 反応に応じたフィードバック　etc.  このチュートリアルの試みがどこまでうまくいくかわかりませんが、とりあえずセットアップしてみましょう。\nいきなりやってみるタイプのチュートリアル いきなりセットアップ  この記事ではMacとPsychoPy 2020.2.3を使ってます。この際なので、PsychoPyをアップデートしてください。  https://github.com/kirikuroda/psychopy_coder_demoからファイルをダウンロードして、PCの適当な場所に保存してください。  いきなり実験   先ほどダウンロードしたpsychopy_coder_demo.pyを、PsychoPy Coder（Experiment Runner）で実行してください。\n  すると、短い課題が画面に表示されます。この課題を解説していくので、まずは課題をやってみてください。1分で終わります。\n  （Macで）以下のようなエラーが出る場合は、 こちらのページ（英語）を参考にしてください。\nFile “psychtoolbox/hid.pyc”, line 137, in init File “psychtoolbox/hid.pyc”, line 145, in _create_queue FileNotFoundError: [Errno 2] No such file or directory    実験の構造 実験は終わりましたか？　実験の構造を確認しましょう：\n 参加者のIDを入力 教示が表示される Startをクリックすると課題が始まる 最初に試行数が表示される 次に都市名が表示される どちらの都市の人口が多いかをFかJで回答する 何もせずに5秒以上経つと「Hurry up!」が表示される FかJを押すと、選んだ方の都市が黄色くなり、四角で囲まれる 正解不正解のフィードバックが表示される （裏でその試行のデータが記録される） ※4〜10を繰り返す 実験終了のメッセージが表示される  では、コードを順になぞっていきます。\n解説 ダイアログボックスを呈示する（38–46行目） # ダイアログボックスを呈示し、参加者の情報を入力 subj_info = {\u0026quot;subj_id\u0026quot;: \u0026quot;\u0026quot;, \u0026quot;add_here_what_you_want\u0026quot;: \u0026quot;\u0026quot;} dialogue_box = gui.DlgFromDict(subj_info, order = [\u0026quot;subj_id\u0026quot;, \u0026quot;add_here_what_you_want\u0026quot;]) # OKならID（subj_id）を記録して実験を進める。キャンセルなら実験を中止 if dialogue_box.OK: subj_id = subj_info[\u0026quot;subj_id\u0026quot;] else: core.quit()  参加者の情報を入力するためのダイアログボックスを呈示しています。\nadd_here_what_you_wantと書いてあるように、他に記録したい情報がある場合は、後ろに付け足してください。\nデータファイルの名前を作る（52–67行目） # 現在日時を記録 exp_date = data.getDateStr(\u0026quot;%Y%m%d%H%M%S\u0026quot;) # データファイルを保存するフォルダを作る # フォルダがなければ作る try: os.makedirs(\u0026quot;data/csv\u0026quot;) os.makedirs(\u0026quot;data/log\u0026quot;) # フォルダが既にある場合は何もしない except OSError: pass # データファイルの名前を作る（ID_日付） file_name = subj_id + \u0026quot;_\u0026quot; + exp_date file_name_csv = os.path.join(\u0026quot;data/csv/\u0026quot; + file_name + \u0026quot;.csv\u0026quot;) file_name_log = os.path.join(\u0026quot;data/log/\u0026quot; + file_name + \u0026quot;.log\u0026quot;)  参加者のIDと現在日時からファイル名を作っています。プログラムを実行した日時は、何らかの形で記録しておくようにしましょう。\nCSVファイルに行動データ、logファイルに実験のログを記録することにします。\nクイズの項目を読み込む（69–70行目） # クイズの項目（都市名、人口）を読み込む city = pd.read_csv(\u0026quot;city.csv\u0026quot;)  この実験課題で呈示する項目（CSVファイル）を読み込んでいます。\n画面、マウス、キーボードを設定する（76–80行目） # 画面の座標系　units = \u0026quot;norm\u0026quot; # 画面中心が(0, 0)、X軸が-1〜+1、Y軸が-1〜+1 win = visual.Window(width = 1200, height = 900, units = \u0026quot;norm\u0026quot;) mouse = event.Mouse() kb = keyboard.Keyboard()  PsychoPyでは、ふつうスクリーンをwinとして記録します。\n都市名刺激を設定する（86–103行目） # テキスト刺激の色と日本語フォント color_default, color_highlight = \u0026quot;white\u0026quot;, \u0026quot;yellow\u0026quot; font_ja = \u0026quot;ヒラギノ角ゴシック W3\u0026quot; # 刺激（都市名）　textは毎試行変わるので、後で定義 city_1_text = visual.TextStim(win, font = font_ja) city_2_text = visual.TextStim(win, font = font_ja) # 刺激の呈示位置のカウンターバランス # 都市名をX軸方向にどれくらいずらすか city_nudge_x = 0.5 # 4試行のカウンターバランスをcity_posとして保存 city_pos = [\u0026quot;one_two\u0026quot;, \u0026quot;one_two\u0026quot;, \u0026quot;two_one\u0026quot;, \u0026quot;two_one\u0026quot;] # city_text_posを並び替える city_pos = np.random.permutation(city_pos) # 試行の順序をランダマイズする。trial_order: [3, 2, 0, 1]のようになる trial_order = np.random.permutation(range(len(city)))  テキスト刺激はvisual.TextStim()で作ります。日本語フォントは好きなものに修正してもらって構いません。\nここでは、呈示位置のカウンターバランスと、試行順序のランダマイズもしています2。\nキーを設定する（105–112行目） # キー設定 key_left, key_right = \u0026quot;f\u0026quot;, \u0026quot;j\u0026quot; # 押すべきキーの名前（課題中に呈示しておく） # キーのテキストをY軸方向にどれくらいずらすか key_text_nudge_y = 0.5 key_left_text = visual.TextStim(win, text = \u0026quot;F\u0026quot;, pos = (-city_nudge_x, key_text_nudge_y)) key_right_text = visual.TextStim(win, text = \u0026quot;J\u0026quot;, pos = (city_nudge_x, key_text_nudge_y))  Fが左、Jが右に対応するようにしています。\nまた、課題中に呈示する「F」と「J」の刺激もここで作っています。\n教示を定義する（114–121行目） # 教示を定義 inst_text = visual.TextStim(win, alignText = \u0026quot;left\u0026quot;, anchorHoriz = \u0026quot;center\u0026quot;) inst_text.setText(\u0026quot;\u0026quot;\u0026quot; Which city has a larger population? Select the city by pressing the F or J of the keyboard. Click \u0026quot;Start\u0026quot; and work on the task. \u0026quot;\u0026quot;\u0026quot;)  教示を作っています。日本語だと少しめんどくさいので、英語で書いています。\n.setText()を使うと、TextStimにテキストを埋め込むことができます。\nStartボタンを定義する（123–129行目） # ボックスの線の太さ box_line_width = 10 # 開始ボタンのボックスとテキスト start_pos_y = -0.5 # Y軸座標 start_box = visual.Rect(win, width = 0.2, height = 0.2, pos = (0, start_pos_y), lineWidth = box_line_width) start_text = visual.TextStim(win, text = \u0026quot;Start\u0026quot;, pos = (0, start_pos_y))  Startボタンを定義しています。四角形はvisual.Rect()で作ります。\nその他のテキスト刺激や図形を定義する（131–157行目） # 試行間で呈示するテキスト（テキストの中身は毎試行変えるので、後で定義する） iti_text = visual.TextStim(win) # ITIの長さ iti_length = 2 # どちらの都市名を選んだかを何秒呈示するか confirmation_length = 1 # 選んだ方の都市を囲うボックスを定義 city_box_width, city_box_height = 0.5, 0.2 # ボックスのサイズ city_box_left = visual.Rect(win, width = city_box_width, height = city_box_height, pos = (-city_nudge_x, 0), lineColor = color_highlight, lineWidth = box_line_width ) city_box_right = visual.Rect(win, width = city_box_width, height = city_box_height, pos = (city_nudge_x, 0), lineColor = color_highlight, lineWidth = box_line_width ) # 正解不正解のテキスト correct_text = visual.TextStim(win, text = \u0026quot;Correct!\u0026quot;) wrong_text = visual.TextStim(win, text = \u0026quot;Wrong...\u0026quot;) feedback_length = 1 # プロンプトのテキスト hurry_text = visual.TextStim(win, text = \u0026quot;Hurry up!\u0026quot;, pos = (0, 0.8), color = color_highlight) # time_limit秒経過したらプロンプトを出す time_limit = 5  その他のテキスト刺激や図形を定義しています。\nログファイルを設定する（163–164行目） # ログファイルの設定 file_log = logging.LogFile(file_name_log, level = logging.EXP)  ログファイルを設定しています。実験中に何が起きたかをほぼ自動で記録してくれるので、設定しておくことをおすすめします。\n教示を呈示する（170–190行目） # 教示（無限ループ） while True: # Startにカーソルが載ってたら黄色に if start_box.contains(mouse): start_box.setLineColor(color_highlight) start_text.setColor(color_highlight) # 載ってなければ白に else: start_box.setLineColor(color_default) start_text.setColor(color_default) # 教示とボックスを描画 inst_text.draw() start_box.draw() start_text.draw() win.flip() # 開始ボタンがクリックされたら無限ループを抜ける if mouse.isPressedIn(start_box): break  教示を呈示しています。刺激をdraw()してからwin.flip()するのが基本です。\nStartボタンにカーソルが載ったら色を変えるようにしています。これを応用すると、マウスの位置を記録することができます。\nStartボタンがクリックされたらループを抜けます。\nCSVファイルの1行目に変数名を書き込む（192–199行目） # CSVファイルの先頭行に変数名を書き込む with open(file_name_csv, \u0026quot;a\u0026quot;, encoding = \u0026quot;cp932\u0026quot;) as f: writer = csv.writer(f, lineterminator = \u0026quot;\\n\u0026quot;) writer.writerow([ \u0026quot;subj_id\u0026quot;, \u0026quot;trial\u0026quot;, \u0026quot;city_1\u0026quot;, \u0026quot;city_2\u0026quot;, \u0026quot;population_1\u0026quot;, \u0026quot;population_2\u0026quot;, \u0026quot;choice\u0026quot;, \u0026quot;correct_answer\u0026quot;, \u0026quot;result\u0026quot;, \u0026quot;rt\u0026quot;, \u0026quot;key\u0026quot;, \u0026quot;pos\u0026quot; ])  CSVファイルに変数名を書き込んでいます。データを記録するときは、この書き方を真似するのがおすすめです。\nカーソルを消して課題を始める（205–215行目） # カーソルを消す mouse.setVisible(False) # 課題開始 for trial_index in range(len(city)): # 試行間のテキストを定義して描画 iti_text.setText(str(trial_index + 1) + \u0026quot;/\u0026quot; + str(len(city))) iti_text.draw() win.flip() core.wait(iti_length)  カーソルを消してから、試行のループに移っています。\niti_textを定義し、呈示しています。\ncore.wait(秒数)で、プログラムを指定時間止めることができます。\n都市名を呈示（217–244行目） # 刺激テキストをセット city_1 = city[\u0026quot;city_1\u0026quot;][trial_order[trial_index]] city_2 = city[\u0026quot;city_2\u0026quot;][trial_order[trial_index]] city_1_text.setText(city_1) city_2_text.setText(city_2) # ついでに人口と正解も記録しておく population_1 = city[\u0026quot;population_1\u0026quot;][trial_order[trial_index]] population_2 = city[\u0026quot;population_2\u0026quot;][trial_order[trial_index]] if population_1 \u0026gt; population_2: answer = \u0026quot;city_1\u0026quot; else: answer = \u0026quot;city_2\u0026quot; # 刺激の位置のカウンターバランス if city_pos[trial_index] == \u0026quot;one_two\u0026quot;: city_1_text.setPos((-city_nudge_x, 0)) city_2_text.setPos((city_nudge_x, 0)) else: city_1_text.setPos((city_nudge_x, 0)) city_2_text.setPos((-city_nudge_x, 0)) # 刺激を描画 city_1_text.draw() city_2_text.draw() key_left_text.draw() key_right_text.draw() win.flip()  都市名刺激を定義・描画したり、課題に関連するデータを記録したりしています。\n.setPos()を使うと、刺激の呈示位置を変更することができます。\n開始時間を記録し、キーボードをリセット（246–251行目） # 回答を待ち始めた時間をresp_onsetとして記録 resp_onset = core.Clock() # キー押しをリセット kb.getKeys([key_left, key_right], waitRelease = False) kb.clock.reset()  刺激呈示の開始時間を記録し、キーボードをリセットしています。\nここでキーボードをリセットしないと、次の試行にキー押しが引き継がれてしまいます。忘れないようにしましょう。\n回答を待つ（253–318行目） # 回答を待つ（無限ループ） while True: # FかJのキー押しを待つ key_pressed = kb.getKeys(keyList = [key_left, key_right], waitRelease = False) # もしFかJが押されたら if len(key_pressed) \u0026gt; 0: # 反応時間を記録 rt = key_pressed[0].rt # どっちのキーを押したかをkeyとして記録 # カウンターバランスに応じて、どっちの都市を選んだかをchoiceとして記録 if key_pressed[0].name == key_left: key = key_left if city_pos[trial_index] == \u0026quot;one_two\u0026quot;: choice = \u0026quot;city_1\u0026quot; else: choice = \u0026quot;city_2\u0026quot; else: key = key_right if city_pos[trial_index] == \u0026quot;one_two\u0026quot;: choice = \u0026quot;city_2\u0026quot; else: choice = \u0026quot;city_1\u0026quot; # 結果を記録 if choice == answer: result = \u0026quot;correct\u0026quot; else: result = \u0026quot;wrong\u0026quot; # 選んだ方の都市名を黄色にする if choice == \u0026quot;city_1\u0026quot;: city_1_text.setColor(color_highlight) else: city_2_text.setColor(color_highlight) # 選んだ方の都市を囲う四角を描画 if key == key_left: city_box_left.draw() else: city_box_right.draw() # その他の刺激も描画して、1秒間呈示 city_1_text.draw() city_2_text.draw() key_left_text.draw() key_right_text.draw() win.flip() core.wait(confirmation_length) # 刺激の色をリセットし、無限ループから抜ける city_1_text.setColor(color_default) city_2_text.setColor(color_default) break # ※time_limitを過ぎたらプロンプトを出す if resp_onset.getTime() \u0026gt; time_limit: city_1_text.draw() city_2_text.draw() key_left_text.draw() key_right_text.draw() hurry_text.draw() win.flip()  回答を待ちます。反応があったらテキストを黄色にし、四角で囲みます。5秒経過したらプロンプトを出すようにしています。\nコードは長めですが、ここでのキー押し判定や条件分岐は汎用性が高いです。というか、ほとんどの実験はこういう（長い）パーツの組み合わせからできています。\nフィードバックをし、各試行のデータを記録（320–338行目） # 正解不正解のフィードバックを呈示 if result == \u0026quot;correct\u0026quot;: correct_text.draw() else: wrong_text.draw() win.flip() core.wait(feedback_length) # CSVファイルにデータを記録 with open(file_name_csv, \u0026quot;a\u0026quot;, encoding = \u0026quot;cp932\u0026quot;) as f: writer = csv.writer(f, lineterminator = \u0026quot;\\n\u0026quot;) writer.writerow([ subj_id, trial_index, city_1, city_2, population_1, population_2, choice, answer, result, rt, key, city_pos[trial_index] ]) # ログファイルを保存 logging.flush()  正解不正解のフィードバックを出してから、データを記録しています。\nなお、ここでは日本語（都市名）を記録しているので、encoding = \u0026quot;cp932\u0026quot;としていますが、ふつうは要らないです。\n実験終了（344–355行目） # 終わりの画面を定義 finish_text = visual.TextStim(win) finish_text.setText(\u0026quot;\u0026quot;\u0026quot; Finish! Thanks! \u0026quot;\u0026quot;\u0026quot;) # 3秒呈示してから実験終了 finish_text.draw() win.flip() core.wait(3) win.close() core.quit()  終了のメッセージを出して、3秒経過したら実験が終わります。\nおわりに このチュートリアルでは割愛した内容もあります。その中で最も重要なものは「関数の自作」です。関数の自作については、 PsychoPy Coderによる心理学実験作成チュートリアルまとめの第7回を読んでください。\nおそらく、このチュートリアルはわかりにくいです。しかし、ここに載っている機能を使えば、大体の社会心理学実験や意思決定実験のたたき台を作ることはできると思います3。かなり駆け足でしたが、このチュートリアルが誰かの役に立てば幸いです。\n  本当は「いきなり」じゃない、すなわち、ある程度想定できたことなんだけど、なかなか準備できないものです。私もそうでした。 \u0026#x21a9;\u0026#xfe0e;\n 試行の順序がシャッフルされているので、本来は呈示位置をシャッフルする必要はないです。一応参考のために書いています。 \u0026#x21a9;\u0026#xfe0e;\n そもそも、この（不親切な）説明に付いて来ようとしている時点でかなりモチベーションがあるはずです。プラスアルファで公式のリファレンスを読めば、実用に耐える実験プログラムをすぐに書けるようになると思います。 \u0026#x21a9;\u0026#xfe0e;\n   ","date":1599004800,"expirydate":-62135596800,"kind":"page","lang":"ja","lastmod":1599004800,"objectID":"d0205e3b624f80b9ed8cafb0063bb3af","permalink":"https://kirikuroda.github.io/post/2020/09/02/psychopy-coder-tutorial/","publishdate":"2020-09-02T00:00:00Z","relpermalink":"/post/2020/09/02/psychopy-coder-tutorial/","section":"post","summary":"いきなりやってみるタイプのCoderチュートリアル","tags":null,"title":"PsychoPy Coderチュートリアル","type":"post"},{"authors":[],"categories":["執筆"],"content":"目次  辞書をあらかじめ決めておく 英英・類語辞典  LEXICO Oxford Learner\u0026rsquo;s Dictionaries   コロケーション  Just the Word Netspeak   フレーズ集  Useful Phrases   おわりに   辞書をあらかじめ決めておく タイトルにもあるように、辞書系ツールを紹介します。しかし正直なところ、自分の使いやすいツールなら何でも良いと思います。\n大事なのは、使う辞書をあらかじめ決めておくことです。いざ英語を書くときに、使う辞書が決まっていないと、辞書自体を探すところから始まってしまい、時間やエネルギーが奪われます。あるいは「よくわからないからとりあえずググるかー」となった場合、裏のない情報に運悪くトラップされてしまうかもしれません。使う辞書を先に厳選しておけば、そのような事態は避けられます。\n辞書系ツールを選ぶに当たり、以下の3つを選定基準としています。\n 無料　現状、辞書系ツールに限って言えば、無料で十分だと思います。ただし、専門家じゃないので断言はできません。 オンライン　デバイスの環境に依存しないのがメリットです。ただし当然ですが、ネットにつながらないと使えません。 NO自動翻訳　機械学習による自動翻訳ツールは除きました。なるべく自力で文章を書いたほうが、長期的には自分のスキルアップにつながると思うからです。しかし、自動翻訳ツールが発達している今、こういう考えは時代遅れになりつつあるのかもしれません。  では、辞書系ツールを紹介します。\n英英・類語辞典 LEXICO  LEXICO\n語義・類語・例文・語源、オールインワンの辞書サイトです。Oxford Dictionaryによって運営されているようです。アメリカ英語・イギリス英語、両方とも載っているので、英単語の意味を調べるときは、とりあえずこれで良いと思います。\n特に、類語（シソーラス）を調べるときには、必ずこのサイトを使っています。検索窓のメニューを「THESAURUS」にすると、類語を検索できます。あるいは、各単語のページの「+ Synonyms」をクリックしても、類語を見ることができます。\n例文が多いのも魅力的です。各単語のページの「+ More example sentences」をクリックすると、どういうニュアンスで使われることが多いかを確認できます。\nOxford Learner\u0026rsquo;s Dictionaries  Oxford Learner\u0026rsquo;s Dictionaries\n名前のとおり、英語学習者用の辞書であるため、LEXICOより情報がコンパクトになっています。単語の意味をさっと確認したいときに便利です。また、平易な英語で語義が説明されているので、LEXICOの説明がわかりにくいときに使うのもおすすめです。頻出単語については、コロケーションや用法も載っています。\nコロケーション Just the Word  Just the Word\n単語を検索するとコロケーションが表示される、というシンプルなサイトです。また、気になったコロケーションをクリックすると、例文も表示されます。コロケーションに関するウェブサイト（そういうのをコーパスっていうんでしょうか？）は他にもありますが、Just the Wordは見た目と機能がシンプルであり、使い方がわかりやすいので気に入っています。\nNetspeak  Netspeak\nある単語や語順の使用頻度を調べたり、比較したりするのに使います。たとえば、「atとin、どっちがよく使われるんだろう？」とか、「この副詞は文のどこに置かれることが多いんだろう？」と思ったときに使います。\nフレーズ集 Useful Phrases  Useful Phrases\n英語論文で頻出のフレーズがまとまっています。\u0026ldquo;English for Writing Research Papers\u0026rdquo;（著・Adrian Wallwork：Springer）という、アカデミック・ライティングの書籍1の付録です。リンク先にある「Free Download: Useful Phrases」をクリックすると、フレーズ集が載ったPDFをダウンロードできます。\n同様のフレーズ集として、 Academic Phrasebankというのがあり、結構多くのブログで紹介されています。フレーズの検索性が低いので、私はあまり使っていませんが、有益なサイトの1つだと思います。\nおわりに 以上、「英語を書かなきゃいけないときに使う辞書系ツール」を紹介しました。このようなツールを使うと、Google検索でなんとなく英語を調べるよりは、裏づけのある良質な情報を得られると思います。ぜひ、自分にピッタリのツールを探してみてください。\n  この\u0026quot;English for Writing Research Papers\u0026quot;という本は、非常に参考になりました。昨年、『 ネイティブが教える 日本人研究者のための論文の書き方・アクセプト術』（講談社、2019）として翻訳されたので、関心のある人は読んでみてください。 \u0026#x21a9;\u0026#xfe0e;\n   ","date":1598572800,"expirydate":-62135596800,"kind":"page","lang":"ja","lastmod":1598572800,"objectID":"d499476429f51be2e95a74b40eb291ca","permalink":"https://kirikuroda.github.io/post/2020/08/28/english-dictionary/","publishdate":"2020-08-28T00:00:00Z","relpermalink":"/post/2020/08/28/english-dictionary/","section":"post","summary":"「これ」という辞書を厳選するのが大事","tags":null,"title":"英語を書かなきゃいけないときに使う辞書系ツール","type":"post"},{"authors":[],"categories":["生活"],"content":"目次  はじめに iPhone SE（第2世代） Apple Watch Series 3 Bellroyのスマホケース AirPods Pro クリアサングラス THERMOSの真空断熱タンブラー 洗顔ネット REALFORCEのキーボード おわりに   はじめに 10万円が給付されたので、改めて身の回りのものを買い揃えました。買ってよかったものを8つ紹介します。\niPhone SE（第2世代）  iPhone SE（第2世代）\n高校の頃から10年近く使ってきたガラケーにガタが来ていました。これまではiPod touchやiPadでごまかしてきたけれど、ようやく腹をくくってiPhoneを買うことにしました。おおむね便利です。\nしかし、iPhoneを導入してから数日後、外出先で通知を確認するのがめちゃくちゃめんどくさい、というか、通知を見逃しやすいということに気がつきました。ガラケーと違い、通知のバイブレーションが短くて弱すぎたのです。\nこの「通知気づきにくい問題」に対処するため、Apple Watchを買いました。\nApple Watch Series 3  Apple Watch Series 3\n買う当初は「スマートウォッチって贅沢すぎでは？」と思っていましが、使っているうちに、この1年でベスト3くらいの買い物だと考えを改めることになりました。以下の3つが特に便利です。\n  必ず通知に気づく：当初の計画通り、通知を見逃さずに済むようになりました。また、必ず通知に気づくようになったことで、メールやメッセージアプリを確認する回数、すなわち、無駄にデバイスを見る時間が減りました。これは時間の節約になるし、精神的な疲労の軽減にもつながると思います。Twitter等のSNSをやっている人だと、この時短効果はより大きいのではないでしょうか。\n  支払いが楽：Apple WatchにモバイルSuicaを入れておけば、レジの読み取り機や自動改札機にタッチするだけで決済できるようになります。スマホだけでもキャッシュレス決済はできるけれど、いちいちスマホを取り出さずに済むのは予想以上に楽です。\n  ライフログを取れる：これは贅沢かもしれないですが、なんとなくライフログを取ることにしました。Autosleep（自動で睡眠時間を記録してくれるアプリ）とLife Cycle（いつ、どこら辺にいたかを記録してくれるアプリ）を使っています。よく運動をする人であれば、この他にも活用法を見いだせると思います。\n  逆に、スマートウォッチを持っていない人は、どうやって通知を確認しているのでしょうか？　いちいちスマホを開くのが無駄だと感じている場合は、購入を考えても良いかもしれません。\nBellroyのスマホケース  Phone Case – 3 Card\n名前の通り、背面にカードを3枚入れられるスマホケースです。このケースの中に、クレジットカード・学生証・大学生協の組合員証を入れています。これのおかげで財布をほぼ使わなくなったし、近場に行くときには財布を持つことすらなくなりました。\nこのスマホケースは10000円します。カードを入れられるスマホケースで、もっと安いものはいくらでも見つかると思います。実際、私も「さすがに贅沢では」と悩みましたが、ふだん安物買いの銭失いで失敗することが多いので、思い切って買うことにしました。長く使いたいです。\nAirPods Pro  AirPods Pro\nめちゃくちゃ良いです。ノイズキャンセリング性能が良いのはもちろんのこと、装着感が軽いのが何より素晴らしいです。自分は音楽をほぼ聞かないし、かなりいい値段もするけれど、それでも買って良かったと思います。\nクリアサングラス 日差しがまぶしすぎるので、例年、夏になるとサングラスをかけています。しかし、今年はマスクを着けなければいけないので、サングラスをかけると不審者に見えてしまうという問題が生じました。\nそこで、クリアサングラス（透明なサングラス）を買いました。見た目にはふつうの眼鏡なので、マスクと合わせても不審者感は全くないです。地味にいい買い物でした。\nTHERMOSの真空断熱タンブラー  真空断熱タンブラー\n真空断熱タンブラーこそ、「地味に生活のクオリティを上げてくれるアイテム」の筆頭だと思います。これまで2年くらい、サーモスのステンレス製タンブラーを使ってきました。今回買い替えたのは、（おそらく）経年劣化のために保冷効果が弱まってきたからです。\n今までのステンレス製とは違い、今回買ったのは陶器っぽいマットな仕上がりで、飲み口も柔らかくなっています。他にも色や素材にバリエーションがあるので、気になった方は調べてみてください。\n洗顔ネット 持っている人からしたら当たり前のことですが、洗顔ネットを使うと「どこにこんな泡があったんだ！？」というレベルでもこもこ泡立ちます。はじめて使ったとき、この数ヶ月で一番びっくりしました。値段も全然高くないし、一度買えば数年から一生は使えると思うので、買ってよかったです。\nREALFORCEのキーボード  REALFORCE TKL SA for Mac\nREALFORCEというのは、有名なキーボードブランドの1つです。HHKBというブランドもありますが、個人的には、REALFORCEのほうが軽くて好みです。\nそれなりに文章に接する職業の人間、すなわち博士課程の院生なら、高めのキーボードを買ったほうが良いと思います。ふつうのキーボードより手への負担が減るだけでなく、文章を書くこと自体がなんとなく楽しくなります。\nちなみに、同じメーカーでもキーボードの種類が多いので、買うときは公式サイトやネットの情報をよく調べるようにしてください。\nおわりに どのアイテムもそれなりに贅沢ですが、地味に、でも確実に生活のクオリティを上げてくれます。いいものを買ってるので、それに見合った仕事をしたいです。\n","date":1598313600,"expirydate":-62135596800,"kind":"page","lang":"ja","lastmod":1598313600,"objectID":"7c502b1e8613bba095b543961b33f327","permalink":"https://kirikuroda.github.io/post/2020/08/25/mustbuy-2020-summer/","publishdate":"2020-08-25T00:00:00Z","relpermalink":"/post/2020/08/25/mustbuy-2020-summer/","section":"post","summary":"どのアイテムも地味に生活のクオリティを上げてくれます","tags":null,"title":"大学院生が（いまさら）買ってよかったもの8選","type":"post"},{"authors":[],"categories":["プレゼンテーション"],"content":"数年前のことですが、データ可視化・報告・ggplot2の初歩をまとめました。 こちらで読むことができます。\n","date":1598054400,"expirydate":-62135596800,"kind":"page","lang":"ja","lastmod":1598054400,"objectID":"48010d3382f20e4e52b81302fde410f9","permalink":"https://kirikuroda.github.io/post/2020/08/22/datareporting/","publishdate":"2020-08-22T00:00:00Z","relpermalink":"/post/2020/08/22/datareporting/","section":"post","summary":"ggplot2の基礎","tags":null,"title":"データの可視化 まとめ","type":"post"},{"authors":[],"categories":["執筆"],"content":"2年ぶりにウェブサイトをリニューアルしました。リニューアルにあたり、かねがね気になっていた Hugo Academicというテンプレートと、 blogdown（Rのパッケージ）を使うことにしました。\nサイト構築の詳しい手順は説明しませんが、1日から2日で一通り作ることができました。もう少し時間をかければ、配色やフォントを自分好みにカスタマイズできそうです。\nそこまで労せずして、自分にしてはオシャレ（？）なサイトを作ることができて良かったです。くわえて、Markdown / R Markdownで記事を書くことができるのも嬉しいポイントです。気が向いたらなにか書きたいです。\n","date":1597968000,"expirydate":-62135596800,"kind":"page","lang":"ja","lastmod":1597968000,"objectID":"c5ebfd85737971cb06831e46addf5b81","permalink":"https://kirikuroda.github.io/post/2020/08/21/hugo-academic/","publishdate":"2020-08-21T00:00:00Z","relpermalink":"/post/2020/08/21/hugo-academic/","section":"post","summary":"Hugo Academicとblogdownがおすすめ","tags":null,"title":"Hugo Academicでウェブサイトをリニューアルしました","type":"post"},{"authors":["Kiri Kuroda","Yoshio Kamijo","Tatsuya Kameda"],"categories":null,"content":"","date":1586908800,"expirydate":-62135596800,"kind":"page","lang":"ja","lastmod":1586908800,"objectID":"db1dbbf5b1bea1a434ccd9a4f382a2ea","permalink":"https://kirikuroda.github.io/publication/kuroda2020investor/","publishdate":"2020-04-15T00:00:00Z","relpermalink":"/publication/kuroda2020investor/","section":"publication","summary":"Trust is a vital element of any society. Previous studies using trust games have provided insight into understandings of trusting behavior. However, investors' behaviors can be confounded by their risk preferences in the game, and little is known about the relationship between stake size and beliefs of others' good intentions underlying trust. We thus used a variant of the trust game and conducted two experiments to examine how stake size affects investors' beliefs about receivers' trustworthiness, with model‐based analyses. We showed that, when holding all else equal, investors trusted more, but their expectations of reciprocation declined as stake size increased. However, actual receivers' reciprocation rates showed the opposite trend to investors' pessimistic beliefs. Furthermore, following previous studies in social psychology, we hypothesized that investors' social preferences (social value orientation) moderated the beliefs underlying trust, but they had no explanatory powers in investors' expectations of reciprocation. These results suggest that peoples' naive beliefs about stake size play a more important role in trust decisions than expected.","tags":null,"title":"Investor's Pessimistic and False Belief About Trustworthiness and Stake Size in Trust Decision","type":"publication"},{"authors":["Kiri Kuroda","Tatsuya Kameda"],"categories":null,"content":"","date":1567296000,"expirydate":-62135596800,"kind":"page","lang":"ja","lastmod":1567296000,"objectID":"a397c82ab5310cf19f8ff5a2efed513a","permalink":"https://kirikuroda.github.io/publication/kuroda2019you/","publishdate":"2019-09-01T00:00:00Z","relpermalink":"/publication/kuroda2019you/","section":"publication","summary":"Predation risk is a significant concern when social animals including humans engage in foraging. When people search for resources together, individuals often find themselves in a producer–scrounger game, in which some individuals bear the cost of risk monitoring while others can free ride on those efforts. A theoretically rational strategy is to mix foraging and risk monitoring randomly with the same probability across all members, but such uncoordinated action often yields inefficiencies of under- or over-supply of risk monitoring in a group. Here, we examined whether people could spontaneously develop a coordinated risk-monitoring system, alternating vigilance and foraging in a pair. Given that human cooperation is vulnerable to fear of exploitation and emotional arousal under risk, we hypothesized that such sources of anxiety would be potential disruptors to coordination. In a laboratory experiment, two participants worked on a “treasure hunt” task simultaneously, in which they chose between low or high vigilance against predators during foraging without verbal communication. If one chose high vigilance with personal cost, it yielded a spillover benefit to the other. Besides behavioral choices, each participant's physiological arousal (skin conductance response) and cognitive effort (tonic pupil dilation) were measured during the task. Results showed that some pairs were actually able to develop a role-alternating system over time through tacit coordination, but coordinated action was also vulnerable to anxiety and mistrust among participants. Overall, these results imply that, besides the mutual behavioral control that often characterizes repeated interaction, cognitive control of emotional arousal may be a critical psychological factor for the emergence of coordinated cooperation.","tags":null,"title":"You Watch My Back, I'll Watch Yours: Emergence of Collective Risk Monitoring Through Tacit Coordination in Human Social Foraging","type":"publication"},{"authors":["Gregory A. Bryant","Daniel M. T. Fessler","...","Kiri Kuroda","...","Yi Zhou"],"categories":null,"content":"","date":1532476800,"expirydate":-62135596800,"kind":"page","lang":"ja","lastmod":1532476800,"objectID":"34399f7cf276aada85e50a0ae1bc4df3","permalink":"https://kirikuroda.github.io/publication/bryant2018perception/","publishdate":"2018-07-25T00:00:00Z","relpermalink":"/publication/bryant2018perception/","section":"publication","summary":"Laughter is a nonverbal vocalization occurring in every known culture, ubiquitous across all forms of human social interaction. Here, we examined whether listeners around the world, irrespective of their own native language and culture, can distinguish between spontaneous laughter and volitional laughter—laugh types likely generated by different vocal-production systems. Using a set of 36 recorded laughs produced by female English speakers in tests involving 884 participants from 21 societies across six regions of the world, we asked listeners to determine whether each laugh was real or fake, and listeners differentiated between the two laugh types with an accuracy of 56% to 69%. Acoustic analysis revealed that sound features associated with arousal in vocal production predicted listeners’ judgments fairly uniformly across societies. These results demonstrate high consistency across cultures in laughter judgments, underscoring the potential importance of nonverbal vocal communicative phenomena in human affiliation and cooperation.","tags":null,"title":"The Perception of Spontaneous and Volitional Laughter Across 21 Societies","type":"publication"}]