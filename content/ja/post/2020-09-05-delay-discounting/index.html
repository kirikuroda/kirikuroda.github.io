---
title: 認知モデルのパラメタを最尤推定する
author: ''
date: '2020-09-05'
slug: mle-delay-discounting
categories:
  - 実験
tags:
subtitle: "遅延割引課題を例として使います"
summary: "遅延割引課題を例として使います"
image:
  placement: 1
  focal_point: "Center"
  preview_only: false
output:
  blogdown::html_page:
    toc: true
draft: false
---


<div id="TOC">
<ul>
<li><a href="#はじめに">はじめに</a><ul>
<li><a href="#背景">背景</a></li>
<li><a href="#このページの概要">このページの概要</a></li>
</ul></li>
<li><a href="#遅延割引のモデルを解説">遅延割引のモデルを解説</a><ul>
<li><a href="#遅延割引課題とは">遅延割引課題とは</a></li>
<li><a href="#遅延割引のモデル">遅延割引のモデル</a></li>
<li><a href="#肢選択のモデル">2肢選択のモデル</a></li>
</ul></li>
<li><a href="#実際に遅延割引パラメタを推定する">実際に遅延割引パラメタを推定する</a><ul>
<li><a href="#実験データを作ってみる">実験データを作ってみる</a></li>
<li><a href="#素朴にパラメタを推定してみる">素朴にパラメタを推定してみる</a></li>
<li><a href="#尤度を計算する">尤度を計算する</a></li>
<li><a href="#対数尤度を計算する">対数尤度を計算する</a></li>
<li><a href="#optimでパラメタを推定する">optimでパラメタを推定する</a></li>
</ul></li>
<li><a href="#おわりに">おわりに</a></li>
</ul>
</div>

<div id="はじめに" class="section level1">
<h1>はじめに</h1>
<div id="背景" class="section level2">
<h2>背景</h2>
<p>いま一部の心理学領域で、認知モデルを立ててそのパラメタを推定する、あるいは、複数のモデルの良さを比較する、というデータ分析がスタンダードになりつつあります。また、その分析手法として、主にStanを使ったベイズ推定が取り上げられるようになっています。</p>
<p><strong>しかし、一体どれだけの人（特に学部生）がベイズ推定についていけているでしょうか？</strong>　実際には、「ベイズ推定どころか最尤推定って何？　具体的にはどう計算するの？　どういうコードを書けばいいの？　そもそも認知モデルって何？」となってしまう<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a>場合が多いのでは？、というのが私の肌感覚です。</p>
<p>そういう「置いてけぼり感」を覚えてしまうことに無理はないです。現状、心理学（特に社会心理学）の授業で、認知モデルに関するトレーニングを受ける機会は少ないからです<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a>。</p>
<p><br></p>
</div>
<div id="このページの概要" class="section level2">
<h2>このページの概要</h2>
<p>そこでこのページでは、<strong>遅延割引課題</strong>を例として、認知モデルのパラメタをどうやって<strong>最尤推定</strong>するかを、具体的に見ていくことにします。推定にはRを使います。</p>
<p>なお、この課題については、『<a href="http://www.asakura.co.jp/books/isbn/978-4-254-12842-0/" title="社会科学のためのベイズ統計モデリング">社会科学のためのベイズ統計モデリング</a>』の第9章を参考にしています。より詳しく知りたい方は、そちらを読んでください。</p>
<p><br></p>
</div>
</div>
<div id="遅延割引のモデルを解説" class="section level1">
<h1>遅延割引のモデルを解説</h1>
<div id="遅延割引課題とは" class="section level2">
<h2>遅延割引課題とは</h2>
<p>遅延割引課題とは、「<strong>いますぐに小さい金額をもらうか、だいぶ先になっちゃうけどより大きい金額をもらうか</strong>」のどちらかを選ぶという課題です。</p>
<p>ここでは、「<strong>いますぐにr円をもらうか、n日後に50000円をもらうか</strong>」のどちらかを選ぶことになったとします。もっと具体的に考えるために、以下の2つの例を考えてみましょう。</p>
<p>まず、「<strong>いますぐに5000円をもらうか、30日後に50000円をもらうか</strong>」と聞かれたら、どっちを選びますか？　おそらく、多くの人は「<strong>30日後に50000円</strong>」を選ぶのではないでしょうか。</p>
<p>次に、「<strong>いますぐに45000円をもらうか、720日後に50000円をもらうか</strong>」と聞かれたら、どっちを選びますか？　ここでは逆に、「<strong>いますぐに45000円</strong>」を選ぶ人が多いと思います。</p>
<p>イメージはつきましたか？　この例からわかるように、遅延割引課題は「<strong>長期的利益のために、人々が目先の利益をどれくらい我慢できるか</strong>」を測定するものです。</p>
<p><br></p>
</div>
<div id="遅延割引のモデル" class="section level2">
<h2>遅延割引のモデル</h2>
<p>さて、「<strong>人が長期的な利益をどれくらい良いと感じるか</strong>」は、以下の式（モデル）で表現できるとされています<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a>：</p>
<p><span class="math display">\[
U(A,t) = U(A)\frac{1}{1+kt}
\]</span></p>
<p>それぞれの記号は以下の内容を表しています：</p>
<ul>
<li><p><span class="math inline">\(A\)</span>：金額。ここでは50000円だと考えてください</p></li>
<li><p><span class="math inline">\(t\)</span>：何日後に<span class="math inline">\(A\)</span>（すなわち50000円）をもらえるか</p></li>
<li><p><span class="math inline">\(U(A, t)\)</span>：<span class="math inline">\(t\)</span>日後に<span class="math inline">\(A\)</span>（50000円）をもらった場合の「嬉しさ」<a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a></p></li>
<li><p><span class="math inline">\(U(A)\)</span>：いますぐに<span class="math inline">\(A\)</span>（50000円）をもらった場合の嬉しさ</p></li>
<li><p><span class="math inline">\(k\)</span>：<strong>遅延割引パラメタ</strong></p></li>
</ul>
<p><br></p>
<p>では、この<span class="math inline">\(k\)</span>（遅延割引パラメタ）とは具体的にどういうものなのでしょうか？　それを理解するために、<span class="math inline">\(k\)</span>をいじってみましょう。</p>
<p>下の図の横軸は「t日」、縦軸は「そのとき50000円をもらったときの嬉しさ（すなわち、<span class="math inline">\(U(A,t)\)</span>）」を表しています。ここでは、<span class="math inline">\(t\)</span>日を0〜30で変化させ、<span class="math inline">\(k\)</span>を0から0.5まで0.05刻みで変化させています。</p>
<p>この図からどういうことが読み取れるでしょうか？</p>
<pre class="r"><code>library(tidyverse)

expand_grid(t = 0:30, k = seq(0, 0.5, 0.05)) %&gt;%
  mutate(u = 50000 * (1 / (1 + k * t))) %&gt;%
  ggplot(aes(x = t, y = u, group = k, color = k)) +
  geom_line() +
  scale_color_viridis_c() +
  labs(x = &quot;t（日）&quot;, y = &quot;t日後に50000円もらったときの嬉しさ&quot;) +
  theme_minimal(base_family = &quot;ヒラギノ角ゴシック W3&quot;) +
  theme(axis.text = element_text(color = &quot;#333333&quot;))</code></pre>
<div class="figure"><span id="fig:fig-1"></span>
<img src="/ja/post/2020-09-05-delay-discounting/index_files/figure-html/fig-1-1.png" alt="図1. t日後に50000円もらったときの嬉しさ" width="672" />
<p class="caption">
Figure 1: 図1. t日後に50000円もらったときの嬉しさ
</p>
</div>
<p><br></p>
<p>まず、<span class="math inline">\(t = 0\)</span>のとき、<span class="math inline">\(k\)</span>がどんな値であれ、縦軸（50000円もらったときの嬉しさ）は50000円です。<span class="math inline">\(t = 0\)</span>は「今すぐ」と同じだからです。</p>
<p>次に、<span class="math inline">\(t\)</span>が大きくなるほど、「<span class="math inline">\(t\)</span>日後に50000円」の嬉しさは低くなっていることがわかります。</p>
<p>また、<span class="math inline">\(k\)</span>が大きくなるほど（線が明るい色になるほど）、「<span class="math inline">\(t\)</span>日後に50000円」の嬉しさは低くなっています。これを引っ張って考えると、「<strong><span class="math inline">\(k\)</span>が大きい人ほど、今すぐの利益に目がくらんでしまいがち</strong>」ということになります<a href="#fn5" class="footnote-ref" id="fnref5"><sup>5</sup></a>。</p>
<p><br></p>
</div>
<div id="肢選択のモデル" class="section level2">
<h2>2肢選択のモデル</h2>
<p>では次に「2つの選択肢（目先の利益 vs. 長期的な利益）をどうやって選ぶか」のモデルを考えてみましょう。</p>
<p>ここでは「今すぐ5000円をもらうか、1ヶ月後に50000円をもらうか」を選ぶ状況を例としてみます。私たちは多くの場合、「1ヶ月後に50000円」を選ぶでしょう。</p>
<p>しかし、人間というものは、そこまで完璧ではありません。もし「ねえ、今すぐ5000円あげるけど、欲しいよね？」と100回も聞かれたら、何回かは誘惑にかられて「今すぐ5000円」を選んでしまうかもしれません。</p>
<p>このような現象を表すため、よくロジスティック関数<a href="#fn6" class="footnote-ref" id="fnref6"><sup>6</sup></a>というものが用いられます。遅延割引課題の例では、以下のように書くことができます。</p>
<p><span class="math display">\[
P_{d} = \frac{1}{1+\exp(-\beta[U(A^{d})-U(A^{s})])}
\]</span></p>
<p>記号の意味は以下のとおりです。</p>
<ul>
<li><p><span class="math inline">\(P_{d}\)</span>：遅延報酬（<span class="math inline">\(t\)</span>日後に50000円）を選ぶ確率（0〜1の値）</p></li>
<li><p><span class="math inline">\(U(A^{d})\)</span>：遅延報酬をもらった時の嬉しさ</p></li>
<li><p><span class="math inline">\(U(A^{s})\)</span>：即時報酬（今すぐの報酬）をもらった時の嬉しさ</p></li>
<li><p><span class="math inline">\(\beta\)</span>：逆温度パラメタ（<strong>嬉しさの差分</strong>にどれくらい敏感に反応するか）</p></li>
</ul>
<p><br></p>
<p>詳しくは「ロジスティック関数」などで調べてほしいのですが、この式で大事なのは以下の2点です。</p>
<ol style="list-style-type: decimal">
<li><p><strong><span class="math inline">\(U(A^{d})-U(A^{s})\)</span>が大きくなるほど<span class="math inline">\(P_{d}\)</span>も大きくなる。</strong>すなわち、遅延報酬が即時報酬よりも魅力的であるほど、遅延報酬を選ぶ確率が高くなるということです。裏を返すと、即時報酬のほうが魅力的であるほど、遅延報酬を選ぶ確率が低くなる（つまり、即時報酬を選ぶ確率が高くなる）ということも表しています。</p></li>
<li><p><strong><span class="math inline">\(\beta\)</span>が大きいほど、「嬉しさ」の差分に強く反応する。</strong>つまり、<span class="math inline">\(\beta\)</span>が大きい場合、嬉しさの大きい方を忠実に選ぶようになるということです。逆に<span class="math inline">\(\beta\)</span>が0に近いほど、どちらを選ぶかはランダムに近づく（「誘惑に駆られやすくなる」）ということも表しています。</p></li>
</ol>
<p><br></p>
<hr />
<p><br></p>
<p>さて、遅延割引課題を用いた研究で知りたいのは、<strong>ある人（参加者）がどれくらい目先の利益に目がくらみがちか</strong>、そして、<strong>ある人（参加者）がどれくらい「嬉しさ」の差分に強く反応するか</strong>ということです。これを言い換えると、<strong>ある人がどれくらいの<span class="math inline">\(k\)</span>（遅延割引パラメタ）を持っているか</strong>、<strong>ある人がどれくらいの<span class="math inline">\(\beta\)</span>（逆温度パラメタ）を持っているか</strong>ということになります。</p>
<p>認知モデルのパラメタを推定するというのは、まさに「ある人がどれくらいのパラメタ（認知的な傾向）を持っているか」を探ろうとする分析を意味しています。</p>
<p><br></p>
</div>
</div>
<div id="実際に遅延割引パラメタを推定する" class="section level1">
<h1>実際に遅延割引パラメタを推定する</h1>
<div id="実験データを作ってみる" class="section level2">
<h2>実験データを作ってみる</h2>
<p>ここで具体的な分析方法を説明したいのですが、まだ手元にはデータがありません。</p>
<p>そこで、ある1人の参加者が50回の遅延割引課題に取り組んだと仮定します。具体的には「<span class="math inline">\(t\)</span>日後に50000円をもらうか、今すぐ<span class="math inline">\(r\)</span>円をもらうか」を選んだとしましょう。各回で、日数<span class="math inline">\(t\)</span>は｛30, 90, 180, 360, 720｝のいずれか、今すぐの報酬<span class="math inline">\(r\)</span>は｛5000, 1000, …, 50000｝のいずれかとします（5通り×10通りなので50回の課題、ということです）。では、下のコードのように仮想的なデータを作り、<code>data</code>というデータフレームとして保存してみましょう<a href="#fn7" class="footnote-ref" id="fnref7"><sup>7</sup></a>。</p>
<pre class="r"><code>set.seed(1)
data &lt;- expand_grid(
  t = c(30, 90, 180, 360, 720),
  r = seq(5000, 50000, 5000)
  ) %&gt;%
  mutate(
    u_delay = 50000 * (1 / (1 + 0.01 * t)),
    p = 1 / (1 + exp(-0.00005 * (u_delay - r)))
  ) %&gt;%
  group_by(row_number()) %&gt;%
  mutate(choice = rbinom(1, 1, p))</code></pre>
<p><br></p>
<p>では、この参加者は遅延報酬（「<span class="math inline">\(t\)</span>日後に50000円」）を何回選んだのでしょうか？　遅延報酬を選んだ場合、<code>data</code>の<code>choice</code>という変数は<code>1</code>になっています。逆に即時報酬（「すぐに<span class="math inline">\(r\)</span>円」）を選んだ場合、<code>choice</code>は<code>0</code>です。</p>
<p>参加者の選択を下にプロットしてみました。横軸は遅延日数<span class="math inline">\(t\)</span>、縦軸は選択（0か1）、各パネルの上の数字は即時報酬の金額を表しています。</p>
<pre class="r"><code>data %&gt;%
  ggplot(aes(x = t, y = choice)) +
  geom_point() +
  scale_y_continuous(breaks = c(0, 1)) +
  facet_wrap(~r)</code></pre>
<div class="figure"><span id="fig:unnamed-chunk-2"></span>
<img src="/ja/post/2020-09-05-delay-discounting/index_files/figure-html/unnamed-chunk-2-1.png" alt="図2．ある参加者がどれくらい遅延報酬を選んだか" width="672" />
<p class="caption">
Figure 2: 図2．ある参加者がどれくらい遅延報酬を選んだか
</p>
</div>
<p><br></p>
</div>
<div id="素朴にパラメタを推定してみる" class="section level2">
<h2>素朴にパラメタを推定してみる</h2>
<p>さて、どのようにパラメタを推定すればよいのでしょうか？　まず、素朴なアイデアから出発してみます。</p>
<p>たとえば、「なんとなくだけど、<span class="math inline">\(k\)</span>は0.1で、<span class="math inline">\(\beta\)</span>は0.0001じゃね？」と考えたとしましょう。このとき、これらのパラメタの値はどれくらいふさわしいでしょうか？　また、そのふさわしさはどのように評価（計算）されるべきでしょうか？</p>
<p>とりあえず、上で説明した2つのモデルに代入してみましょう。ここでは、「今すぐ5000円」と「30日後に50000円」を比べた場合を考えてみます。</p>
<pre class="r"><code>t &lt;- 30
k &lt;- 0.1
beta &lt;- 0.0001

# u_delay：遅延報酬のU
u_delay &lt;- 50000 * (1 / (1 + 0.1 * t))

# 30日後に50000円を選ぶ確率
p &lt;- 1 / (1 + exp(-beta * (u_delay - 5000)))

print(p)</code></pre>
<pre><code>## [1] 0.6791787</code></pre>
<p><br></p>
<p>さて、<span class="math inline">\(k = 0.1\)</span>、<span class="math inline">\(\beta = 0.0001\)</span>としたとき、遅延報酬を選ぶ確率は0.6791787になりました。では、実際のデータはどうだったでしょうか？（つまり、「今すぐ5000円 vs. 30日後に50000円」のとき、どっちを選んでいたでしょうか？）</p>
<p>図2を見ると、参加者は遅延報酬（30日後に50000円）を選んでいたことがわかります。では、上の計算で出てきた「遅延報酬を選ぶ確率は0.6791787」と「参加者が実際に遅延報酬を選んでいたという事実」はどのように関係しているのでしょうか。</p>
<p>「遅延報酬を選ぶ確率」というのは、「『遅延報酬を選ぶ』という結果が得られる確率」と言い換えることができます。この「『遅延報酬を選ぶ』という結果が得られる確率」は、パラメタ<span class="math inline">\(k\)</span>と<span class="math inline">\(\beta\)</span>を色々な値にすれば、それに応じて様々な値に変動します。</p>
<p>ここで、「参加者が実際に遅延報酬を選んで」いたとしましょう。このとき、適当にパラメタを代入して、「『遅延報酬を選ぶ』という結果が得られる確率」が高かった場合、それは何を意味しているでしょうか。</p>
<p>日常言語で表すと、「参加者は遅延報酬を選んだ。適当にパラメタを代入したら、遅延報酬を選ぶ確率は高いらしい。これって結構近いじゃん」ということになります。さらにこれを引っ張ると、「予結構近いんだから、このパラメタって、もしかして良い線行ってるんじゃね？」となります。逆に、予測が外れた場合は、そのパラメタはあまりよろしくないと言えます。</p>
<p>つまり、「ある結果が得られている。そこで、適当にパラメタを設定したら、その結果が得られる確率も高いようだ。だったら、そのパラメタは『ふさわしい』んじゃないか」ということです。このようなパラメタの「ふさわしさ」（<strong>パラメタを設定したとき、手元のデータが得られる確率</strong>）を真面目に言うと「尤度」になります。また、尤度をもとにパラメタを推定する方法を最尤推定と言います。</p>
<p>この例では、「いま、参加者が遅延報酬を選んだことがわかっている。そこで、<span class="math inline">\(k = 0.1\)</span>、<span class="math inline">\(\beta = 0.0001\)</span>としたとき、遅延報酬を選ぶ確率は0.6791787だった」となります。すなわち、尤度は0.6791787です<a href="#fn8" class="footnote-ref" id="fnref8"><sup>8</sup></a>。</p>
<p><br></p>
</div>
<div id="尤度を計算する" class="section level2">
<h2>尤度を計算する</h2>
<p>では、<span class="math inline">\(k = 0.1\)</span>、<span class="math inline">\(\beta = 0.0001\)</span>とし、全50回の尤度を計算してみましょう。まず、以下のコードを実行します。</p>
<pre class="r"><code>t &lt;- 30
k &lt;- 0.1
beta &lt;- 0.0001

data %&gt;%
  # 遅延報酬のUと、遅延報酬を選ぶ確率pを計算
  mutate(
    u_delay = 50000 * (1 / (1 + k * t)),
    p = 1 / (1 + exp(-beta * (u_delay - r)))
  ) %&gt;%
  # 遅延報酬を選ぶ確率pを抽出
  pull(p)</code></pre>
<pre><code>##  [1] 0.679178699 0.562176501 0.437823499 0.320821301 0.222700139 0.148047198
##  [7] 0.095349465 0.060086650 0.037326887 0.022977370 0.500000000 0.377540669
## [13] 0.268941421 0.182425524 0.119202922 0.075858180 0.047425873 0.029312231
## [19] 0.017986210 0.010986943 0.441064710 0.323695074 0.224986141 0.149714490
## [25] 0.096490497 0.060834074 0.037802587 0.023274618 0.014247244 0.008690106
## [31] 0.409782432 0.296323939 0.203450772 0.134137019 0.085891464 0.053918000
## [37] 0.033411753 0.020535219 0.012556698 0.007653837 0.393766567 0.282619107
## [43] 0.192864008 0.126583888 0.080801479 0.050617863 0.031325176 0.019236783
## [49] 0.011756686 0.007163930</code></pre>
<p><br></p>
<p>上に表示されているのは、遅延報酬を選ぶ確率<span class="math inline">\(p\)</span>です。</p>
<p>しかし、これをそのまま最尤推定に使うことはできません。なぜなら、尤度とは「あるパラメタを設定したときに、<strong>手元の</strong>データが得られる確率」だからです。実験では、参加者が即時報酬を選ぶ場合も当然あるので、その場合は「即時報酬を選ぶ確率」を使わないといけません。したがって、各回の尤度（likelihood）は以下のようになります。</p>
<pre class="r"><code>likelihood &lt;- data %&gt;%
  # 遅延報酬のUと、遅延報酬を選ぶ確率pを計算
  # さらに、参加者の選択に応じて条件分岐をして尤度を計算
  mutate(
    u_delay = 50000 * (1 / (1 + k * t)),
    p = 1 / (1 + exp(-beta * (u_delay - r))),
    likelihood = if_else(choice == 1, p, 1 - p)
  ) %&gt;%
  pull(likelihood)

likelihood</code></pre>
<pre><code>##  [1] 0.67917870 0.56217650 0.43782350 0.67917870 0.22270014 0.85195280
##  [7] 0.90465054 0.06008665 0.03732689 0.97702263 0.50000000 0.37754067
## [13] 0.73105858 0.18242552 0.88079708 0.92414182 0.04742587 0.02931223
## [19] 0.98201379 0.01098694 0.55893529 0.32369507 0.77501386 0.85028551
## [25] 0.90350950 0.93916593 0.96219741 0.97672538 0.01424724 0.99130989
## [31] 0.40978243 0.70367606 0.79654923 0.86586298 0.08589146 0.94608200
## [37] 0.03341175 0.97946478 0.98744330 0.99234616 0.60623343 0.28261911
## [43] 0.19286401 0.87341611 0.91919852 0.05061786 0.96867482 0.98076322
## [49] 0.98824331 0.99283607</code></pre>
<p><br></p>
</div>
<div id="対数尤度を計算する" class="section level2">
<h2>対数尤度を計算する</h2>
<p>では、ここで全50回の尤度を1つの指標にまとめたいと思います（まとめたいですよね？）。このとき、直観的には尤度を足し算すれば良いんじゃないか、と思うかもしれませんが、それは間違いです。</p>
<p>正解は「かけ算」です。詳しい説明は適宜教科書を読むなり、ググってもらえるとありがたいです<a href="#fn9" class="footnote-ref" id="fnref9"><sup>9</sup></a>。簡単な例で言えば、「3回連続でじゃんけんに勝つ確率は？」と聞かれたとき、「1/3を3回足して1」ではなく、「1/3を3回かけ算して1/27」と答えるのが正解になるのも同じ理屈です。</p>
<p>では、上で求めた尤度を全部かけ算してみましょう。</p>
<pre class="r"><code># prod()で、要素を全部かけあわせることになる
prod(likelihood)</code></pre>
<pre><code>## [1] 1.143327e-20</code></pre>
<p><br></p>
<p>これは0.000000000001067125を表しています。</p>
<p>ちっさ！って思うのではないでしょうか。と同時に、「やっぱ、パソコンはこんな細かい計算できて偉いなあ」と思う人がいるかもしれません。</p>
<p>しかし、残念ながらそれは間違いです。あまりに数字が小さいと、パソコンの計算にも誤差が生じてしまいます<a href="#fn10" class="footnote-ref" id="fnref10"><sup>10</sup></a>。</p>
<p>これを防ぐため、尤度を計算するときは、<strong>対数を取る</strong>というのが決まりになっています。なぜなら、かけ算の対数を取ると足し算になるという便利な性質があるからです<a href="#fn11" class="footnote-ref" id="fnref11"><sup>11</sup></a>。対数を取って求めた尤度を「対数尤度（log likelihood）」と言います。</p>
<p>また、対数は単調増加関数なので、「尤度の積が大きい（もっともらしい）場合は、その対数も大きくなる」という関係が成り立ちます。対数、便利です。</p>
<p>では、対数尤度を計算し、全部を足し算してみましょう。</p>
<pre class="r"><code>sum(log(likelihood))</code></pre>
<pre><code>## [1] -45.91776</code></pre>
<p><br></p>
<p>確認のため、尤度を全部掛け算したやつの対数を取ってみましょう。</p>
<pre class="r"><code>log(prod(likelihood))</code></pre>
<pre><code>## [1] -45.91776</code></pre>
<p><br></p>
<p>ちゃんと2つが一致しました。ただし、データの数が多いほどかけ算の誤差は大きくなるので、やはり対数を取ってから足し算をするようにしましょう。</p>
<p><br></p>
</div>
<div id="optimでパラメタを推定する" class="section level2">
<h2>optimでパラメタを推定する</h2>
<p>さて、<span class="math inline">\(k = 0.1\)</span>、<span class="math inline">\(\beta = 0.0001\)</span>としたときの50回の対数尤度は-27.56605になりました。</p>
<p>で？　それが何？</p>
<p>そうです。これだけでは、まだ何も言えていません。他のパラメタの候補も調べないと、どのパラメタが良さそうかはわかりません。</p>
<p>では、どうすればよいでしょうか？　素朴に考えたら、有り得そうな<span class="math inline">\(k\)</span>や<span class="math inline">\(\beta\)</span>を片っ端から代入して対数尤度を計算する、というのが良さそうです。しかし、そんな時間は私たちにはありません。</p>
<p>そこで使うのが、Rの最適化関数<code>optim</code>です。最適化関数とは、ある関数の最大値／最小値を求めるための道具だと考えてください。</p>
<p>いま私たちがやりたいのは、対数尤度が最も大きくなりそうなパラメタ<span class="math inline">\(k\)</span>と<span class="math inline">\(\beta\)</span>の組み合わせを調べるということです。つまり、<code>optim</code>を使って、対数尤度（関数）が最大化されるような<span class="math inline">\(k\)</span>と<span class="math inline">\(\beta\)</span>を見つければ目的達成ということになります。</p>
<p>では、具体的な書き方を説明します。まず、対数尤度関数（<code>ll_delay</code>）を自分で定義します。</p>
<pre class="r"><code># 関数を定義する
ll_delay &lt;- function(param, data) {
  
  # param[1]はk、param[2]はbetaを表している
  # dataは参加者のデータフレームそのものを表している
  
  data %&gt;%
    # 毎回の対数尤度を計算する
    mutate(
      u_delay = 50000 * (1 / (1 + param[1] * t)),
      p = 1 / (1 + exp(-param[2] * (u_delay - r))),
      likelihood = if_else(choice == 1, p, 1 - p),
      ll = log(likelihood)
    ) %&gt;%
    # 最後に全部足し合わせる
    pull(ll) %&gt;%
    sum()
}</code></pre>
<p><br></p>
<p>これを<code>optim</code>に突っ込みます。<code>par</code>には推定したいパラメタの初期値、<code>fn</code>には最適化したい関数を入れます。<code>control = list(fnscale = -1)</code>とすると、関数の最大化が行われるようになります。その他の引数（この例では<code>data</code>）では、<code>ll_delay</code>にどんな引数を渡すかを指示してあげます。</p>
<pre class="r"><code>optim(par = c(0.1, 0.0001), fn = ll_delay, data = data, control = list(fnscale = -1))</code></pre>
<pre><code>## $par
## [1] 0.0132120062 0.0000423154
## 
## $value
## [1] -30.70504
## 
## $counts
## function gradient 
##       89       NA 
## 
## $convergence
## [1] 0
## 
## $message
## NULL</code></pre>
<p><br></p>
<p>結果の<code>par</code>が推定値を表しています。<span class="math inline">\(k\)</span>が0.0132120062、<span class="math inline">\(\beta\)</span>は0.0000423154でした。</p>
<p>では、正解は何だったのでしょうか？　正解は、データを作ったコードの中に隠れています。改めてコードを見てみましょう。</p>
<pre class="r"><code>set.seed(1)
data &lt;- expand_grid(
  t = c(30, 90, 180, 360, 720),
  r = seq(5000, 50000, 5000)
  ) %&gt;%
  mutate(
    u_delay = 50000 * (1 / (1 + 0.01 * t)),
    p = 1 / (1 + exp(-0.00005 * (u_delay - r)))
  ) %&gt;%
  group_by(row_number()) %&gt;%
  mutate(choice = rbinom(1, 1, p))</code></pre>
<p><br></p>
<p>最初は詳しく説明しませんでしたが、このコードでは、遅延割引と2肢選択のモデルを用いて、参加者の選択を仮想的に作っていました。とくに7行目と8行目を見てください。ここでは、参加者が<span class="math inline">\(k=0.01\)</span>、<span class="math inline">\(\beta=0.00005\)</span>というパラメタを持つように設定しています。さて、推定結果は<span class="math inline">\(k=0.0132120062\)</span>、<span class="math inline">\(\beta=0.0000423154\)</span>でした。まあまあ良い線行ってるのではないでしょうか。</p>
<p><br></p>
</div>
</div>
<div id="おわりに" class="section level1">
<h1>おわりに</h1>
<p>ここまで、駆け足で認知パラメタの最尤推定を見てきました。もちろん、まだまだ説明していないトピックはありますが、まずはここらへんの内容を押さえておくのが良いかと思います。</p>
<p><br></p>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>私が学部生の頃もそうでした。たとえば当時、とても偉い工学系の先生に「すみません、単回帰分析の最尤推定ってどうやるんですか？」みたいなことを聞いてたレベルです。ちなみに、単回帰分析の最尤推定は心理統計の教科書に載っているし、ググればすぐに出てくるような内容です。今思えばガチで恥ずかしいですが、「知らぬは一時の恥、聞かぬは一生の恥」です。そんな質問をしていた私ですら、いま一応なんとか生きてます。（以下、かなり脱線します。）わからないことがあったときにおすすめなのは、研究室や学科の先輩に質問することです。もちろんググっても良いのですが、先輩たちも同様の難所を乗り越えている場合が多いので、同じ目線で答えてくれる可能性が高いです。ただし、自分がふだん研究室に行かなかったり、先輩と全然コミュニケーションを取ったりしていないのに、「卒論締切間際に自分が困ったときにだけ質問する」みたいな姿勢は、傍から見ていると「それは虫が良すぎじゃね？」という感じがします。「<strong>ふだんから細かく</strong>」質問する、世間話をしておく（※先輩の機嫌を取るということではないです）、ぐらいのことをやっておいたほうが、長期的には良いと思います。このトピックだけで記事1つ書けそうです。<a href="#fnref1" class="footnote-back">↩︎</a></p></li>
<li id="fn2"><p>まあ、「授業が全てを教えてくれる」という期待・態度がそもそも間違っているという説はあります。結局のところ、研究スキルなんて、試行錯誤で無理くり獲得していくものなのかもしれません。<a href="#fnref2" class="footnote-back">↩︎</a></p></li>
<li id="fn3"><p>この式は、双曲割引（hyperbolic discounting）と言います。<a href="#fnref3" class="footnote-back">↩︎</a></p></li>
<li id="fn4"><p><span class="math inline">\(U\)</span>は「嬉しさ（Ureshisa）」の頭文字のUではなく、本当は「効用（Utility）」の頭文字を表しています。ここで「効用」とか書いちゃうと難しくなるので、「嬉しさ」にしています。<a href="#fnref4" class="footnote-back">↩︎</a></p></li>
<li id="fn5"><p>ちょっとジャンプがあるかもしれませんが、わからなかった場合はゆっくり考えてみてください。日常的な例（？）でいうと、<span class="math inline">\(k\)</span>が大きいほど、「健康診断のため1ヶ月後に3kg痩せるのは、今すぐに飴玉を1個食べるのと等しいと感じてしまう」ということです。このような人は「今すぐ飴玉2個あげるよ」と言われたら、飴玉2個を食べてしまう（目がくらんでしまう）ということになります。逆に<span class="math inline">\(k\)</span>が小さいと、「1ヶ月後に3kg痩せるのは、今すぐ高級マカロン100個を食べるのと等しいと感じる」ということです。このような人は「今すぐマカロン1個あげるよ」と言われても、「そんな少ないマカロンをもらうぐらいなら、我慢して減量したほうがマシ」と返事をして、拒絶することになるでしょう。<a href="#fnref5" class="footnote-back">↩︎</a></p></li>
<li id="fn6"><p>ソフトマックス関数といったほうが厳密かもしれません。詳しくは『社会科学のためのベイズ統計モデリング』を読んだり、「ソフトマックス関数　ロジスティック関数」でググったりしてみてください。<a href="#fnref6" class="footnote-back">↩︎</a></p></li>
<li id="fn7"><p>とりあえずこのコードの意味を意味を理解する必要はないです。<a href="#fnref7" class="footnote-back">↩︎</a></p></li>
<li id="fn8"><p>正直、尤度や最尤推定については他にもっと優れた記事があると思うので、わからなければ適宜ググってもらえると嬉しいです。<a href="#fnref8" class="footnote-back">↩︎</a></p></li>
<li id="fn9"><p>「積事象」や「尤度」でググってみてください。<a href="#fnref9" class="footnote-back">↩︎</a></p></li>
<li id="fn10"><p>これをアンダーフローと言います。たとえば、Rのコンソールに<code>1e-1000</code>とか打ってみて、どうなるかを見てみましょう。<a href="#fnref10" class="footnote-back">↩︎</a></p></li>
<li id="fn11"><p>この説明は端折りますが、一応文系数学の範囲です。「尤度」でググると、この内容は必ず説明されているので、適宜調べてみてください。<a href="#fnref11" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
