[{"authors":null,"categories":null,"content":"黒田起吏は、社会心理学を専攻する大学院生である。黒田は行動実験・アイトラッキング・認知モデリングを用いながら、ヒトの集団意思決定を研究している。\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"ja","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://kirikuroda.github.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"黒田起吏は、社会心理学を専攻する大学院生である。黒田は行動実","tags":null,"title":"Kiri Kuroda","type":"authors"},{"authors":[],"categories":["生活"],"content":"\nタイトルと副題がこの記事の中身の90%以上を表しているので、われながら、これ以上何を書けばいいんだと感じています。とりあえず、どのような経緯でマグカップを購入したかを説明します。\nきっかけ 私が所属している研究室には、同期の学生（男性）が1人います。その同期とは、学部生の頃から約6年間、苦楽をともにしてきました。私がこれまで研究を続けてこられたのには、間違いなく彼の存在がありました。\n今年、その同期が一足先に博士号を取得することになりました。シンプルにおめでたいです。これが祝うべきこと「その1」です。\nまた、彼は、来年度から日本学術振興会特別研究員（PD）として採用されることになりました。素晴らしいです。これが祝うべきこと「その2」です。\nしかも、つい最近、その同期を第一著者とする論文が、ある心理学系の国際誌に掲載されました。博士課程の締めくくりとしては、これ以上ないことです。これが祝うべきこと「その3」です。\nつまり、盆と正月とクリスマスが一緒に来たレベルで、おめでたいことが重なっているということです。また、彼の論文の研究は3つの実験から構成されており、彼がその実験を着実に積み重ねてきたのを、私は間近で見てきました。彼の門出を祝うだけでなく、これまでの頑張りをねぎらいたいという気持ちもありました。\nそこで思いついたのが、この記事のタイトルの「論文がプリントされたマグカップ」です。\nScienceGritでマグカップを購入 このマグカップは、ScienceGritというサイトで買うことができます。ScienceGritは、研究者向けのギフトを展開している商品サイトです。\n私が購入したマグカップのページは、Personalized Gifts \u0026gt; Personalized Publication Mugsというカテゴリの\u0026ldquo;Customize with your paper: Custom Graph Mug\u0026rdquo;です。\n購入は簡単です。\n マグカップのサイズを選択（11オンスか15オンス）：11オンスだと、幅と高さが同じくらいです。15オンスだと少し縦長で、若干ビールジョッキのようにも見えます。私は11オンスを買いました。ちょうどよかったと思います。  個数を入力  論文のPDFをアップロード：向こうの人が論文のアブストラクトを切り取って、マグカップにプリントしてくれます。  画像ファイルをアップロード：上記のアブストラクトに加え、ここでアップロードした画像ファイルもマグカップにプリントされます。論文に登場する図表などがおすすめです。  メッセージを入力（任意）：好きなメッセージを入力できます。ただし、私は入力しませんでした。  商品の購入を確定する際は、住所を英語で入力することをおすすめします。私は日本語で入力したのですが、後でScienceGritの担当者から「英語で頼むわ」とお願いされることになりました。\n商品を購入すると、数日後にScienceGritの担当者から「マグカップのプリント、こんな感じでいいですか？」というメール（英語）と完成品の画像が届きます。もし修正してほしければ、ここでお願いをすることになります。私は、とくに修正点がないと思ったので、そのまま配送してくださいと返事をしました。\n商品はラトビアから発送され、たしか2〜3週間くらいで届きました。なお、配達日時の指定はできません。梱包は簡素でしたが、傷や破損はありませんでした。\n私が買ったマグカップの画像は載せられませんが、Twitterには色々な画像が載っています。Twitterで「ScienceGrit」などと調べてみてください。ざっと見た感じ、（Twitterにしては珍しく？）ポジティブなツイートばかりで、買った人たちは基本的に満足しているようでした。\nおわりに 実際、マグカップを同期に渡したら、彼はとても喜んでいました。ここまで喜んでくれるとは思ってもいなかったので、ついでに私も嬉しくなりました。贈ってよかったです。\nなお、調べてはいませんが、マグカップに画像をプリントするといった注文は国内でもできると思います。もしかしたら、そのほうがScienceGritより安くて速いかもしれません。\nしかし、ScienceGritは研究者のニーズ（心情？）を理解しています。そうでもなければ「アブストをプリントしたマグカップ」なんて作るわけがありません。ScienceGritで商品を購入すると国外輸送費がかかるし、商品が届くのも遅いかもしれませんが、私はそういうサービスを応援したいです。もし今後マグカップを買うときが来たら、またScienceGritを使おうと思います。\n以上、マグカップの購入体験談でした。博士号取得や論文アクセプトのお祝いには、うってつけのアイテムだと思います。\n","date":1612183605,"expirydate":-62135596800,"kind":"page","lang":"ja","lastmod":1612183605,"objectID":"8ff3b3f1f68f467990f2390c0faa3030","permalink":"https://kirikuroda.github.io/post/2021/02/01/sciencegrit-publication-mug/","publishdate":"2021-02-01T21:46:45+09:00","relpermalink":"/post/2021/02/01/sciencegrit-publication-mug/","section":"post","summary":"ScienceGritというサイトで購入しました","tags":["論文","ギフト","ScienceGrit","買ってよかったもの"],"title":"論文がプリントされたマグカップを贈ったら喜んでもらえたというおはなし","type":"post"},{"authors":[],"categories":["プレゼンテーション"],"content":"はじめに 今年は、色々と参考になるプレゼン本にめぐり会えました。そこで、これまで読んだ本の中で参考になったものをリストアップしておきます。\nなお、ネットにも色々な情報は載っていますが、本のほうが体系的にまとまっているので、結局は買ったほうが早いという印象です。\nスライドのデザイン・構成 感覚にまかせるのではなく、ある程度の知識をもってスライドを作ると、より自信を持てるようになると思います。\n『一生使える見やすい資料のデザイン入門』 『見やすいプレゼン資料の作り方』というスライドの書籍版です。今年の夏に出会いました。\nスライドを作る上で基本的なことがまとまっていたり、かゆいところに手の届くパワポの機能が紹介されたりしているので、とりあえず読んでおいて損はないと思いました。ちなみに、Amazon Primeに加入しているとKindle版を無料で読めます（2020年12月27日現在）。\n『伝わるデザインの基本 増補改訂版 よい資料を作るためのレイアウトのルール』 『伝わるデザイン 研究発表のユニバーサルデザイン』というウェブサイトの書籍版です。\n最初に紹介した『一生使える見やすい資料のデザイン入門』よりも研究者向けに書かれていて、かつ説明が丁寧な雰囲気があります。また、おそらくウェブサイト版よりも情報が豊富です。\nこの本は3〜4年前に買いましたが、今でも買って良かったと思います。発表資料を作る上で、これはマストで読んだほうが良いとおすすめできる1冊です。\n『できる研究者のプレゼン術 スライドづくり、話の組み立て、話術』 \u0026ldquo;Better Presentations: A Guide for Scholars, Researchers, and Wonks\u0026quot;という本の日本語版です。今年の夏に原著を買おうとしたら、この日本語版（2020年3月出版）を見つけました。\nこれは、上で紹介した『伝わるデザインの基本』の次に読むべき本という感じです。『伝わるデザインの基本』は十分素晴らしいですが、その教えを忠実に守るだけだと、良くも悪くもデザインや構成が大人しくなってしまう気がします。つまり「デザインを全く考えていない悲惨なスライド」よりは改善されるものの、「聴衆をグイグイ惹きつける」まではいかないかもしれない、ということです1。\nこの『できる研究者のプレゼン術』で紹介されているデザインやテクニックは、『伝わるデザインの基本』より洗練された雰囲気を醸し出しています2。もう少し上のレベルを目指したい人（まさに今の私）におすすめの1冊です。\n\u0026ldquo;English for Presentations at International Conferences (Second Edition)\u0026rdquo; 著者はアカデミックライティングを教えている人で、これまでに多くのライティング本を出版しています。この\u0026quot;English for Presentations\u0026quot;もその1つとして書かれたものです。実際にこの本でも「どういうセリフを言ったり、どういう文章をスライドに載せたりするべきか」を教えてくれます。\nただ個人的には、むしろプレゼンの構成について有意義なアドバイスを提示していると思いました。なお『できる研究者のプレゼン術』がデザインにウェイトを置いているのに対し、\u0026ldquo;English for Presentations\u0026quot;は、プレゼンの構成や聴衆とのコミュニケーションに関するパートが手厚いです。英語に関する本ですが、日本語の発表でも使える考え方やテクニックが載っています。\nデータビジュアライゼーション 多くのプレゼン本は、スライドにおける視覚的要素（図表・デザイン）の重要性を強調しています。データビジュアライゼーションのオタクになる必要はないですが、その基礎は押さえておいたほうが良いと思います。\n\u0026ldquo;Fundamentals of Data Visualization\u0026rdquo; Fundamentals of Data Visualization\nデータビジュアライゼーションで大事なポイントをまとめたウェブサイトです。同名の書籍もあります。中身は英語ですが、悪いグラフと良いグラフを対比させながら説明してくれているので、そこまでしっかり文章を追わなくても理解できます。\nこの本の最大の特徴は「データビジュアライゼーションのツールについては説明していない」という点にあります。この方針はもしかすると不親切かもしれないですが、ツールを問わず適用できるので、汎用性（学習効果）は高いです。\nまた著者は、グラフの正確さやわかりやすさだけでなく、美醜という点も評価の対象にしています。「正しいしわかりやすいかもしれないけど、見ていて微妙な気持ちになるグラフ」というのはたしかに存在するので、これは重要な観点だと思います。\nとりあえずこれさえ読んでおけば間違いないという1冊です。\n『Rグラフィックス クックブック 第2版 ggplot2によるグラフ作成のレシピ集』 R Graphics Cookbook, 2nd editionというウェブサイト（本）の日本語版書籍です。\nデータビジュアライゼーションではどんなツールを使ってもいいと思いますが、私はRのggplot2を使っています。これを一通り写経すれば、ggplot2はかなり身につくと思います。またサンプルが豊富なので、グラフの引き出しが自分の中で増えるはずです。1つのスライドや論文で同じ形式のグラフを繰り返し使うと野暮ったくなるので3、引き出しが多いのに越したことはないです。\nおわりに COVID-19の影響で、今年自分が参加した学会はすべてオンライン開催でした。オンライン学会ではスライドがウェブサイト上で公開され、いつもよりじっくり吟味できる／される気がしました。\n「観たい発表を自発的に選べる」という今の学会形式がしばらく続くとすると、これまで以上に発表のわかりやすさと面白さが求められるようになると思いました（つまらなくわかりにくい発表だと、閲覧すらされない可能性があるということです）。もちろん、見た目やデザインの良し悪しと研究内容の良し悪しは独立にジャッジすべきという考えもあると思いますし、その考えに共感もします。一方で「それならデザインも内容も良ければOKじゃないか？（脳筋的発想）」という気もしています。なかなか難しい問題です。\nただ、プレゼン本を読んでいると、発表のデザインや構成を考えるのが少しずつ楽しくなってきたのも確かです。今後も精進しようと思います。\n  あくまで個人的意見です。もちろん、自分の発表もまだその境地には達していないです。 \u0026#x21a9;\u0026#xfe0e;\n 「洗練された雰囲気」は完全に私の主観にすぎないですが、結局スライドの見た目はそういう感覚の問題であるとも思います。 \u0026#x21a9;\u0026#xfe0e;\n これは\u0026quot;Fundamentals of Data Visualization\u0026quot;の教えの1つです。 \u0026#x21a9;\u0026#xfe0e;\n   ","date":1609040455,"expirydate":-62135596800,"kind":"page","lang":"ja","lastmod":1609040455,"objectID":"9e3e51de2e2b43022897882fc4d88350","permalink":"https://kirikuroda.github.io/post/2020/12/27/presentation-books/","publishdate":"2020-12-27T12:40:55+09:00","relpermalink":"/post/2020/12/27/presentation-books/","section":"post","summary":"プレゼンの道はまだまだ長いが、とりあえずこれは読んで良かったという個人的セレクト","tags":["プレゼンテーション","学会発表","スライド","データビジュアライゼーション","可視化","ggplot2","R","PowerPoint"],"title":"学会の発表資料を作るときに参考になった本","type":"post"},{"authors":[],"categories":["実験"],"content":"この記事のサマリー   jsPsychとFirebaseでウェブ実験を実施した\n  私の浅知恵のせいで、データが十分に記録されないという悲劇が生じた\n  結局のところ、国里先生の記事や安藤先生の記事を忠実に守れば悲劇なんて起こらないということがわかった\n  自己紹介 Online Psychological Experiment Advent Calendar の21日目に登録した黒田起吏と申します。社会情報の処理過程や集団意思決定時の認知過程について、主に実験室実験（ヒトを対象とした認知行動実験）を用いて研究してきました。\n先日、jsPsychとFirebaseを用いたウェブ実験を行ったところ、大きなミスを犯しました。この記事ではその経緯と原因を説明します。反面教師にしていただければ幸いです。\nウェブ実験の背景 COVID-19の影響で、ヒトを対象とした実験室実験を実施しにくくなっています。近頃では、共用のキーボードからコロナに感染した話もあるそうです。この状況では、協力してくださる方々が安心して実験に参加できるとは思えないため、いまは実験室実験を自粛しています。\nそのため今年度から、私はjsPsychとFirebaseを用いてウェブ実験を行ってきました。実施方法については、国里先生の記事や安藤先生の記事をご覧ください。\n結論としては、2つの記事の内容を忠実に守ればトラブルは起きません。しかし、私は浅知恵を働かせてしまい、記事の内容を忠実には守りませんでした。結局のところ、それが悲劇の原因でした。1\n悲劇の経緯 2020年12月14日、ウェブ実験の参加者をメールで募集しました。このウェブ実験は「参加希望者がURLからサイトにアクセスし、自分のペースで80試行の課題に取り組む」というシンプルなものです。サンプルサイズについては、63名を計画していました。\nしばらくして、70名程度（脱落者や外れ値がいるかもしれないと考えていたので、63名より若干多めに実施）のデータが集まりました。FirebaseからJSONデータをエクスポートし、データが記録されているかを確認しました。\nすると、下の図のような結果が得られました。X軸は各参加者、Y軸は記録できた試行数を表しています。\nOMG。全80試行を記録できた人が、たった8人しかいません。残り60数名では、大なり小なり欠損が生じてしまっています。なぜこのようなことが起きてしまったのでしょうか？\n悲劇の原因と解決策 結論から言うと、Firebaseへのデータの記録方法が間違っていたのが原因でした。まず、正解（国里先生の記事や安藤先生の記事で紹介されている方法）を見ていきます。\n正解 正解のやり方では、以下のようなコードでデータを記録します。\njsPsych.init({ timeline: timeline, on_finish: function() { firebase.database().ref(exp_id).set({ data: jsPsych.data.get().values() }) } });  これが意味しているのは「実験が全て終わったら、これまでのデータを一括で記録する」ということです。こうしておけば、データはきちんと記録されます。\n不正解（今回やってしまったこと） しかし、私は浅知恵を働かせてしまいました。どのような浅知恵だったかを説明します。\nまず、国里先生の記事や安藤先生の記事を読んだとき、素朴にこう思いました。\n この方法（正解バージョン）だと、実験の途中で参加者が脱落したら、データを記録できないのでは？？？\n 実際、この考え自体は正しいです（おそらくは。でもあまり自信ないです）。そこで私は「各試行が終わるたびにデータを記録」するようにしました。下のようなコードです。\n// 以下のコードは不正解なので真似しないでください!! // 80試行のタイムライン。 // 各試行の最後（参加者の反応後）にこれまでの全てのデータを逐一記録 const timeline = { timeline: [fixation, stimulus, response], timeline_variables: variables, // 80試行のパラメタ repetitions: 1, on_finish: function() { firebase.database().ref(exp_id).set({ data: jsPsych.data.get().values() }) } }; // 実験の最後にもついでにデータを記録 jsPsych.init({ timeline: timeline, on_finish: function() { firebase.database().ref(exp_id).set({ data: jsPsych.data.get().values() }) } });  実際、このコードは動くし、データも記録できます。\nただしそれは、1人ないし少人数が同時に取り組んでいる場合だけです。つまり、自分1人でテストする限り、このコードが不具合を起こすことはほとんどありません。しかし、複数人が同時にこの課題に取り組むと、データの欠損が生じてしまいます。\n何が起きていたか？ データの欠損に気がついたとき、私は以下の3つが原因かもしれないと考えました。\n Firebaseが無料プランだった（しょぼかった） 同時に参加した人数が多く、それがサーバに負荷をかけた データを毎試行（頻繁に）記録して、それがサーバに負荷をかけた  まず1についてです。Firebaseに詳しくないので確かなことは言えませんが「課金すればいいんじゃないの」と思い、早速自分のクレジットカードを登録しました。つまり1の原因は（おそらく）潰せました。\n次に2についてです。同時接続数を確認したところ、最大12人が同時接続していたことがわかりました。12人が同時接続するだけでサーバが駄目になるサービスだとしたら、Firebaseの商売は成り立ってないはずなので、この可能性はかなり低いと考えました。ただ、一応その可能性は切り捨てませんでした。\n残った最後の可能性として、3の原因が一番大きそうだと考えるに至りました。これまで私は「毎試行データを記録するぐらい、Firebaseサンなら大丈夫でしょ」と思っていましたが、そうではないかもしれないと考え直したということです。\nテスト テスト状況 上の説を検証するため、12月16日にテストを行いました。テスト状況は以下のとおりです。\n Firebaseのプランをアップグレードした 実験データを「実験の最後に一括で記録」するようにした。つまり、国里先生や安藤先生のやり方に忠実に従ったということ 13人（研究室のメンバーなど）に頼み、同時にウェブサイトに接続して課題に取り組んでもらった  結果 記録されたデータを確認したところ、13人全員のデータ全てが記録されていました。つまり成功です。\n考察 コードを正解バージョンに修正したことがかなり有効だったと考えられます。もちろんFirebaseのアップグレードが有効だったという可能性は残っていますが、とにかくデータ欠損の問題は解決しました。\n教訓 まとめると、jsPsychとFirebaseで実験を実施するときは、\n 国里先生の記事や安藤先生の記事にあるように「実験が全て終わったときにデータを記録する」のが良い （インテンシブに）データを取る場合、Firebaseは一応有料プランにしておくのが良いかもしれない。無料枠の中で済んだらどうせお金を払わずに済むので（おそらくは。詳しくはご自身の責任でお調べください）  ということになります。\n私のようにやらかす人は少ないとは思いますが、念のためご注意いただければと思います。\n  『文化がヒトを進化させた』の書評にもあるように、まさに「累積的に進化した文化のコンテンツは個人の体験や思考の限界を超えて有用なことが多いからなぜそうするのかわからなくてもまず従うことが有利」ということでした。つまり「よくわからんけど、とりあえず言い伝えには従っておく」が正解だったということです。 \u0026#x21a9;\u0026#xfe0e;\n   ","date":1608100427,"expirydate":-62135596800,"kind":"page","lang":"ja","lastmod":1608100427,"objectID":"12b335e477bb314e9d4c73a0b139ccf1","permalink":"https://kirikuroda.github.io/post/2020/12/16/jspsych-firebase/","publishdate":"2020-12-16T15:33:47+09:00","relpermalink":"/post/2020/12/16/jspsych-firebase/","section":"post","summary":"素人の浅知恵が悲惨な結果をもたらすという格好の事例。他山の石にしてください","tags":["jsPsych","JavaScript","Firebase","実験","ウェブ実験","失敗談"],"title":"jsPsych + Firebaseでやらかした話","type":"post"},{"authors":["Kiri Kuroda","Yukiko Ogura","Akitoshi Ogawa","Tomoya Tamei","Kazushi Ikeda","Tatsuya Kameda"],"categories":null,"content":"","date":1603324800,"expirydate":-62135596800,"kind":"page","lang":"ja","lastmod":1603324800,"objectID":"e25eb466bc724fdfd4b1717410e30a00","permalink":"https://kirikuroda.github.io/publication/kuroda2020bilateral/","publishdate":"2020-04-15T00:00:00Z","relpermalink":"/publication/kuroda2020bilateral/","section":"publication","summary":"Social norms, including values, beliefs and even perceptions about the world, are preserved and created through repeated interactions between individuals. However, whereas neuro-cognitive research on social norms has used the “unilateral influence” paradigm focusing on people’s reactions to extant standards, little is known about how our basic perceptions and judgments are shaped as new norms through bilateral interaction. Here, using a simple estimation task, we investigated the formation of perceptual norms using two experiments coupled with computational modeling. In the behavioral experiment, participants in dyads repeatedly estimated the number of dots on a screen and viewed each other’s answers. In the fMRI experiment, we manipulated the interaction process by pairing each participant with a computer agent which adjusted its estimations reciprocally to participants’ estimations (bilateral agent) or did not (unilateral). The results indicated that only the bilateral interaction yielded convergence of participants’ covert psychophysical functions (relations between subjective estimations and the actual number of dots) as well as overt behavioral responses within a pair. Bilateral interaction also increased the stability (reliability) of the covert function within each individual after interaction. Neural activity in the mentalizing network (right temporoparietal junction and dorsomedial prefrontal cortex) during interaction modulated the stabilization of the psychophysical function. These results imply that bilateral interaction helps people to cognitively anchor their views with each other. Such spontaneous perspective sharing can yield a shared covert “generative model” that enables endogenous agreement on totally new targets ― one of the key features of social norms.","tags":null,"title":"Bilateral (but Not Unilateral) Interaction Creates and Cements Norms at the Covert Psychophysical Level: A Behavioral and an Fmri Study","type":"publication"},{"authors":null,"categories":["実験"],"content":" はじめに 背景 いま一部の心理学領域で、認知モデルを立ててそのパラメタを推定する、あるいは、複数のモデルの良さを比較する、というデータ分析がスタンダードになりつつあります。また、その分析手法として、主にStanを使ったベイズ推定が取り上げられるようになっています。\nしかし、一体どれだけの人（特に学部生）がベイズ推定についていけているでしょうか？　実際には、「ベイズ推定どころか最尤推定って何？　具体的にはどう計算するの？　どういうコードを書けばいいの？　そもそも認知モデルって何？」となってしまう1場合が多いのでは？、というのが私の肌感覚です。\nそういう「置いてけぼり感」を覚えてしまうことに無理はないです。現状、心理学（特に社会心理学）の授業で、認知モデルに関するトレーニングを受ける機会は少ないからです2。\n\n このページの概要 そこでこのページでは、遅延割引課題を例として、認知モデルのパラメタをどうやって最尤推定するかを、具体的に見ていくことにします。推定にはRを使います。\nなお、この課題については、『社会科学のためのベイズ統計モデリング』の第9章を参考にしています。より詳しく知りたい方は、そちらを読んでください。\n\n  遅延割引のモデルを解説 遅延割引課題とは 遅延割引課題とは、「いますぐに小さい金額をもらうか、だいぶ先になっちゃうけどより大きい金額をもらうか」のどちらかを選ぶという課題です。\nここでは、「いますぐにr円をもらうか、n日後に50000円をもらうか」のどちらかを選ぶことになったとします。もっと具体的に考えるために、以下の2つの例を考えてみましょう。\nまず、「いますぐに5000円をもらうか、30日後に50000円をもらうか」と聞かれたら、どっちを選びますか？　おそらく、多くの人は「30日後に50000円」を選ぶのではないでしょうか。\n次に、「いますぐに45000円をもらうか、720日後に50000円をもらうか」と聞かれたら、どっちを選びますか？　ここでは逆に、「いますぐに45000円」を選ぶ人が多いと思います。\nイメージはつきましたか？　この例からわかるように、遅延割引課題は「長期的利益のために、人々が目先の利益をどれくらい我慢できるか」を測定するものです。\n\n 遅延割引のモデル さて、「人が長期的な利益をどれくらい良いと感じるか」は、以下の式（モデル）で表現できるとされています3：\n\\[ U(A,t) = U(A)\\frac{1}{1+kt} \\]\nそれぞれの記号は以下の内容を表しています：\n \\(A\\)：金額。ここでは50000円だと考えてください\n \\(t\\)：何日後に\\(A\\)（すなわち50000円）をもらえるか\n \\(U(A, t)\\)：\\(t\\)日後に\\(A\\)（50000円）をもらった場合の「嬉しさ」4\n \\(U(A)\\)：いますぐに\\(A\\)（50000円）をもらった場合の嬉しさ\n \\(k\\)：遅延割引パラメタ\n  \nでは、この\\(k\\)（遅延割引パラメタ）とは具体的にどういうものなのでしょうか？　それを理解するために、\\(k\\)をいじってみましょう。\nFigure 1の横軸は「t日」、縦軸は「そのとき50000円をもらったときの嬉しさ（すなわち、\\(U(A,t)\\)）」を表しています。ここでは、\\(t\\)日を0〜30で変化させ、\\(k\\)を0から0.5まで0.05刻みで変化させています。\nこの図からどういうことが読み取れるでしょうか？\nlibrary(tidyverse) expand_grid(t = 0:30, k = seq(0, 0.5, 0.05)) %\u0026gt;% mutate(u = 50000 * (1 / (1 + k * t))) %\u0026gt;% ggplot(aes(x = t, y = u, group = k, color = k)) + geom_line() + scale_color_viridis_c() + labs(x = \u0026quot;t（日）\u0026quot;, y = \u0026quot;t日後に50000円もらったときの嬉しさ\u0026quot;) + theme_minimal(base_family = \u0026quot;ヒラギノ角ゴシック W3\u0026quot;) + theme(axis.text = element_text(color = \u0026quot;#333333\u0026quot;))  Figure 1: t日後に50000円もらったときの嬉しさ  \nまず、\\(t = 0\\)のとき、\\(k\\)がどんな値であれ、縦軸（50000円もらったときの嬉しさ）は50000円です。\\(t = 0\\)は「今すぐ」と同じだからです。\n次に、\\(t\\)が大きくなるほど、「\\(t\\)日後に50000円」の嬉しさは低くなっています。\nまた、\\(k\\)が大きくなるほど（線が明るい色になるほど）、「\\(t\\)日後に50000円」の嬉しさは低くなっています。これを引っ張って考えると、「\\(k\\)が大きい人ほど、今すぐの利益に目がくらんでしまいがち」ということになります5。\n\n 2肢選択のモデル では次に「2つの選択肢（目先の利益 vs. 長期的な利益）をどうやって選ぶか」のモデルを考えてみましょう。\nここでは「今すぐ5000円をもらうか、1ヶ月後に50000円をもらうか」を選ぶ状況を例とします。私たちは多くの場合、「1ヶ月後に50000円」を選ぶでしょう。\nしかし、人間というものは、そこまで完璧ではありません。もし「ねえ、今すぐ5000円あげるけど、欲しいよね？」と100回も聞かれたら、何回かは誘惑にかられて「今すぐ5000円」を選んでしまうかもしれません。\nこのような現象を表すため、よくロジスティック関数6というものが用いられます。遅延割引課題の例では、以下のように書くことができます。\n\\[ P_{d} = \\frac{1}{1+\\exp(-\\beta[U(A^{d})-U(A^{s})])} \\]\n記号の意味は以下のとおりです。\n \\(P_{d}\\)：遅延報酬（\\(t\\)日後に50000円）を選ぶ確率（0〜1の値）\n \\(U(A^{d})\\)：遅延報酬をもらった時の嬉しさ\n \\(U(A^{s})\\)：即時報酬（今すぐの報酬）をもらった時の嬉しさ\n \\(\\beta\\)：逆温度パラメタ（嬉しさの差分にどれくらい敏感に反応するか）\n  \n詳しくは「ロジスティック関数」などで調べてほしいのですが、この式で大事なのは以下の2点です。\n\\(U(A^{d})-U(A^{s})\\)が大きくなるほど\\(P_{d}\\)も大きくなる。すなわち、遅延報酬が即時報酬よりも魅力的であるほど、遅延報酬を選ぶ確率が高くなるということです。裏を返すと、即時報酬のほうが魅力的であるほど、遅延報酬を選ぶ確率が低くなる（つまり、即時報酬を選ぶ確率が高くなる）ということも表しています。\n \\(\\beta\\)が大きいほど、「嬉しさ」の差分に強く反応する。つまり、\\(\\beta\\)が大きい場合、嬉しさの大きい方を忠実に選ぶようになるということです。逆に\\(\\beta\\)が0に近いほど、どちらを選ぶかはランダムに近づく（「嬉しさ」の影響力が弱くなり、選択肢をでたらめに選ぶようになる）ということも表しています。\n  \n\nさて、遅延割引課題を用いた研究で知りたいのは、ある人（参加者）がどれくらい目先の利益に目がくらみがちか、そして、ある人（参加者）がどれくらい「嬉しさ」の差分に強く反応するかということです。これを言い換えると、ある人がどれくらいの\\(k\\)（遅延割引パラメタ）を持っているか、ある人がどれくらいの\\(\\beta\\)（逆温度パラメタ）を持っているかということになります。\n認知モデルのパラメタを推定するというのは、まさに「ある人がどれくらいのパラメタ（認知的な傾向）を持っているか」を探ろうとする分析を意味しています。\n\n  実際に遅延割引パラメタを推定する 実験データを作ってみる ここで具体的な分析方法を説明したいのですが、まだ手元にはデータがありません。\nそこで、ある1人の参加者が50回の遅延割引課題に取り組んだと仮定します。具体的には「\\(t\\)日後に50000円をもらうか、今すぐ\\(r\\)円をもらうか」を選んだとしましょう。各回で、日数\\(t\\)は｛30, 90, 180, 360, 720｝のいずれか、今すぐの報酬\\(r\\)は｛5000, 1000, …, 50000｝のいずれかとします（5通り×10通りなので50回の課題、ということです）。では、下のコードのように仮想的なデータを作り、dataというデータフレームとして保存してみましょう7。\nset.seed(1) data \u0026lt;- expand_grid( t = c(30, 90, 180, 360, 720), r = seq(5000, 50000, 5000) ) %\u0026gt;% mutate( u_delay = 50000 * (1 / (1 + 0.01 * t)), p = 1 / (1 + exp(-0.00005 * (u_delay - r))) ) %\u0026gt;% group_by(row_number()) %\u0026gt;% mutate(choice = rbinom(1, 1, p)) \nでは、この参加者は遅延報酬（「\\(t\\)日後に50000円」）を何回選んだのでしょうか？　遅延報酬を選んだ場合、dataのchoiceという変数は1になっています。逆に即時報酬（「すぐに\\(r\\)円」）を選んだ場合、choiceは0です。\n参加者の選択を下にプロットしてみました。横軸は遅延日数\\(t\\)、縦軸は選択（0か1）、各パネルの上の数字は即時報酬の金額を表しています。\ndata %\u0026gt;% ggplot(aes(x = t, y = choice)) + geom_point() + scale_y_continuous(breaks = c(0, 1)) + facet_wrap(~r)  Figure 2: ある参加者がどれくらい遅延報酬を選んだか  \n 素朴にパラメタを推定してみる さて、どのようにパラメタを推定すればよいのでしょうか？　まず、素朴なアイデアから出発してみます。\nたとえば、「なんとなくだけど、\\(k\\)は0.1で、\\(\\beta\\)は0.0001じゃね？」と考えたとしましょう。このとき、これらのパラメタの値はどれくらいふさわしいでしょうか？　また、そのふさわしさはどのように評価（計算）されるべきでしょうか？\nとりあえず、上で説明した2つのモデルに代入してみましょう。ここでは、「今すぐ5000円」と「30日後に50000円」を比べた場合を考えてみます。\nt \u0026lt;- 30 k \u0026lt;- 0.1 beta \u0026lt;- 0.0001 # u_delay：遅延報酬のU u_delay \u0026lt;- 50000 * (1 / (1 + 0.1 * t)) # 30日後に50000円を選ぶ確率 p \u0026lt;- 1 / (1 + exp(-beta * (u_delay - 5000))) print(p) ## [1] 0.6791787 \nさて、\\(k = 0.1\\)、\\(\\beta = 0.0001\\)としたとき、遅延報酬を選ぶ確率は0.6791787になりました。では、実際のデータはどうだったでしょうか？ つまり、「今すぐ5000円 vs. 30日後に50000円」のとき、どっちを選んでいたでしょうか？\nFigure 2を見ると、参加者が遅延報酬（30日後に50000円）を選んでいたということがわかります。では、上の計算で出てきた「遅延報酬を選ぶ確率は0.6791787」と「参加者が実際に遅延報酬を選んでいたという事実」はどのように関係しているのでしょうか。\n「遅延報酬を選ぶ確率」というのは、「『遅延報酬を選ぶ』という結果が得られる確率」と言い換えることができます。この「『遅延報酬を選ぶ』という結果が得られる確率」は、パラメタ\\(k\\)と\\(\\beta\\)を色々な値にすれば、それに応じて様々な値に変動します。\nここで、「参加者が実際に遅延報酬を選んで」いたとしましょう。このとき、適当にパラメタを代入して、「『遅延報酬を選ぶ』という結果が得られる確率」が高かった場合、それは何を意味しているでしょうか。\n日常言語で表すと、「参加者は遅延報酬を選んでいた。適当にパラメタを代入したら、遅延報酬を選ぶ確率は高いらしい。これって実際のデータと結構近いじゃん」ということになります。さらにこれを引っ張ると、「結構近いんだから、このパラメタって、もしかして良い線行ってるんじゃね？」となります。逆に、予測が外れた場合は、そのパラメタはあまりよろしくないと言えます。\nつまり、「ある結果が得られている。そこで、適当にパラメタを設定したら、その結果が得られる確率も高いようだ。だったら、そのパラメタは『ふさわしい』んじゃないか」ということです。このようなパラメタの「ふさわしさ」（パラメタを設定したとき、手元にあるデータが得られる確率）を真面目に言うと「尤度」になります。また、尤度をもとにパラメタを推定する方法を最尤推定と言います。\nこの例では、「いま、参加者が遅延報酬を選んだことがわかっている。そこで、\\(k = 0.1\\)、\\(\\beta = 0.0001\\)としたとき、遅延報酬を選ぶ確率は0.6791787だった」ということになります。すなわち、尤度は0.6791787です8。\n\n 尤度を計算する では、\\(k = 0.1\\)、\\(\\beta = 0.0001\\)とし、全50回の尤度を計算してみましょう。まず、以下のコードを実行します。\nt \u0026lt;- 30 k \u0026lt;- 0.1 beta \u0026lt;- 0.0001 data %\u0026gt;% # 遅延報酬のUと、遅延報酬を選ぶ確率pを計算 mutate( u_delay = 50000 * (1 / (1 + k * t)), p = 1 / (1 + exp(-beta * (u_delay - r))) ) %\u0026gt;% # 遅延報酬を選ぶ確率pを抽出 pull(p) ## [1] 0.679178699 0.562176501 0.437823499 0.320821301 0.222700139 0.148047198 ## [7] 0.095349465 0.060086650 0.037326887 0.022977370 0.500000000 0.377540669 ## [13] 0.268941421 0.182425524 0.119202922 0.075858180 0.047425873 0.029312231 ## [19] 0.017986210 0.010986943 0.441064710 0.323695074 0.224986141 0.149714490 ## [25] 0.096490497 0.060834074 0.037802587 0.023274618 0.014247244 0.008690106 ## [31] 0.409782432 0.296323939 0.203450772 0.134137019 0.085891464 0.053918000 ## [37] 0.033411753 0.020535219 0.012556698 0.007653837 0.393766567 0.282619107 ## [43] 0.192864008 0.126583888 0.080801479 0.050617863 0.031325176 0.019236783 ## [49] 0.011756686 0.007163930 \n上に表示されているのは、遅延報酬を選ぶ確率\\(p\\)です。\nしかし、これをそのまま最尤推定に使うことはできません。なぜなら、尤度とは「あるパラメタを設定したときに、手元にあるデータが得られる確率」だからです。実験では、参加者が即時報酬を選ぶ場合も当然あるので、その場合は「即時報酬を選ぶ確率」を使わないといけません。したがって、各回の尤度（likelihood）は以下のようになります。\nlikelihood \u0026lt;- data %\u0026gt;% # 遅延報酬のUと、遅延報酬を選ぶ確率pを計算 # さらに、参加者の選択に応じて条件分岐をして尤度を計算 mutate( u_delay = 50000 * (1 / (1 + k * t)), p = 1 / (1 + exp(-beta * (u_delay - r))), likelihood = if_else(choice == 1, p, 1 - p) ) %\u0026gt;% pull(likelihood) likelihood ## [1] 0.67917870 0.56217650 0.43782350 0.67917870 0.22270014 0.85195280 ## [7] 0.90465054 0.06008665 0.03732689 0.97702263 0.50000000 0.37754067 ## [13] 0.73105858 0.18242552 0.88079708 0.92414182 0.04742587 0.02931223 ## [19] 0.98201379 0.01098694 0.55893529 0.32369507 0.77501386 0.85028551 ## [25] 0.90350950 0.93916593 0.96219741 0.97672538 0.01424724 0.99130989 ## [31] 0.40978243 0.70367606 0.79654923 0.86586298 0.08589146 0.94608200 ## [37] 0.03341175 0.97946478 0.98744330 0.99234616 0.60623343 0.28261911 ## [43] 0.19286401 0.87341611 0.91919852 0.05061786 0.96867482 0.98076322 ## [49] 0.98824331 0.99283607 \n 対数尤度を計算する では、ここで全50回の尤度を1つの指標にまとめたいと思います（まとめたいですよね？）。このとき、直観的には尤度を足し算すれば良いんじゃないか、と思うかもしれませんが、それは間違いです。\n正解は「かけ算」です。詳しい説明は適宜教科書を読むなり、ググってもらえるとありがたいです9。簡単な例で言えば、「3回連続でじゃんけんに勝つ確率は？」と聞かれたとき、「1/3を3回足して1」ではなく、「1/3を3回かけ算して1/27」と答えるのが正解になるのと同じ理屈です。\nでは、上で求めた尤度を全部かけ算してみましょう。\n# prod()で、要素を全部かけあわせることになる prod(likelihood) ## [1] 1.143327e-20 \nこれは0.00000000000000000001143327を表しています。\nちっさ！って思うのではないでしょうか。と同時に、「やっぱ、パソコンはこんな細かい計算できて偉いなあ」と思う人がいるかもしれません。\nしかし、残念ながらそれは間違いです。あまりに数字が小さいと、パソコンの計算にも誤差が生じてしまいます10。\nこれを防ぐため、尤度を計算するときは、対数を取るというのが決まりになっています。なぜなら、かけ算の対数を取ると足し算になるという便利な性質があるからです11。対数を取って求めた尤度を「対数尤度」と言います。\nまた、対数は単調増加関数なので、「尤度の積が大きい（もっともらしい）場合は、その対数も大きくなる」という関係が成り立ちます。対数、便利です。\nでは、対数尤度を計算し、全部を足し算してみましょう。\nsum(log(likelihood)) ## [1] -45.91776 \n確認のため、尤度を全部掛け算したやつの対数を取ってみましょう。\nlog(prod(likelihood)) ## [1] -45.91776 \nちゃんと2つが一致しました。ただし、データの数が多いほどかけ算の誤差は大きくなるので、やはり対数を取ってから足し算をするようにしましょう。\n\n optimでパラメタを推定する さて、\\(k = 0.1\\)、\\(\\beta = 0.0001\\)としたときの50回の対数尤度は-45.91776になりました。\nで？　それが何？\nそうです。これだけでは、まだ何も言えていません。他のパラメタの候補も調べないと、どのパラメタが良さそうかはわかりません。\nでは、どうすればよいでしょうか？　素朴に考えたら、有り得そうな\\(k\\)や\\(\\beta\\)を片っ端から代入して対数尤度を計算する、というのが良さそうです。しかし、そんな時間は私たちにはありません。\nそこで使うのが、Rの最適化関数optimです。最適化関数とは、ある関数の最大値／最小値を求めるための道具だと考えてください。\nいま私たちがやりたいのは、対数尤度が最も大きくなりそうなパラメタ\\(k\\)と\\(\\beta\\)の組み合わせを調べるということです。つまり、optimを使って、対数尤度（関数）が最大化されるような\\(k\\)と\\(\\beta\\)を見つければ目的達成ということになります。\nでは、具体的な書き方を説明します。まず、対数尤度関数（ll_delay）を自分で定義します。\n# 関数を定義する ll_delay \u0026lt;- function(param, data) { # param[1]はk、param[2]はbetaを表している # dataは参加者のデータフレームそのものを表している data %\u0026gt;% # 毎回の対数尤度を計算する mutate( u_delay = 50000 * (1 / (1 + param[1] * t)), p = 1 / (1 + exp(-param[2] * (u_delay - r))), likelihood = if_else(choice == 1, p, 1 - p), ll = log(likelihood) ) %\u0026gt;% # 最後に全部足し合わせる pull(ll) %\u0026gt;% sum() } \nこれをoptimに突っ込みます。parには推定したいパラメタの初期値、fnには最適化したい関数を入れます。control = list(fnscale = -1)とすると、関数の最大化が行われるようになります。その他の引数（この例ではdata）では、ll_delayにどんな引数を渡すかを指示してあげます。\noptim(par = c(0.1, 0.0001), fn = ll_delay, data = data, control = list(fnscale = -1)) ## $par ## [1] 0.0132120062 0.0000423154 ## ## $value ## [1] -30.70504 ## ## $counts ## function gradient ## 89 NA ## ## $convergence ## [1] 0 ## ## $message ## NULL \n結果のparが推定値を表しています。\\(k\\)が0.0132120062、\\(\\beta\\)は0.0000423154でした。\nでは、正解は何だったのでしょうか？　正解は、データを作ったコードの中に隠れています。改めてコードを見てみましょう。\nset.seed(1) data \u0026lt;- expand_grid( t = c(30, 90, 180, 360, 720), r = seq(5000, 50000, 5000) ) %\u0026gt;% mutate( u_delay = 50000 * (1 / (1 + 0.01 * t)), p = 1 / (1 + exp(-0.00005 * (u_delay - r))) ) %\u0026gt;% group_by(row_number()) %\u0026gt;% mutate(choice = rbinom(1, 1, p)) \n最初は詳しく説明しませんでしたが、このコードでは、遅延割引と2肢選択のモデルを用いて、参加者の選択を仮想的に作っていました。とくに7行目と8行目を見てください。ここでは、参加者が\\(k=0.01\\)、\\(\\beta=0.00005\\)というパラメタを持つように設定しています。さて、推定結果は\\(k=0.0132120062\\)、\\(\\beta=0.0000423154\\)でした。まあまあ良い線行ってるのではないでしょうか。\n\n  おわりに ここまで、駆け足で認知パラメタの最尤推定を見てきました。もちろん、まだまだ説明していないトピックはありますが、まずはここらへんの内容を押さえておくのが良いかと思います。\n\n  私が学部生の頃もそうでした。たとえば当時、とても偉い工学系の先生に「すみません、単回帰分析の最尤推定ってどうやるんですか？」みたいなことを聞いてたレベルです。ちなみに、単回帰分析の最尤推定は心理統計の教科書に載っているし、ググればすぐに出てくるような内容です。今思えばガチで恥ずかしいですが、「知らぬは一時の恥、聞かぬは一生の恥」です。そんな質問をしていた私ですら、いま一応なんとか生きてます。（以下、かなり脱線します。）わからないことがあったときにおすすめなのは、研究室や学科の先輩に質問することです。もちろんググっても良いのですが、先輩たちも同様の難所を乗り越えている場合が多いので、同じ目線で答えてくれる可能性が高いです。ただし、自分がふだん研究室に行かなかったり、先輩と全然コミュニケーションを取ったりしていないのに、「卒論締切間際に自分が困ったときにだけ質問する」みたいな姿勢は、傍から見ていると「それは虫が良すぎじゃね？」という感じがします。「ふだんから細かく」質問する、世間話をしておく（※先輩の機嫌を取るということではないです）、ぐらいのことをやっておいたほうが、長期的には良いと思います。このトピックだけで記事を1つ書けそうです。↩︎\n まあ、「授業が全てを教えてくれる」という期待・態度がそもそも間違っているという説はあります。結局のところ、研究スキルなんて、試行錯誤で無理くり獲得していくものなのかもしれません。↩︎\n この式は、双曲割引（hyperbolic discounting）と言います。↩︎\n \\(U\\)は「嬉しさ（Ureshisa）」の頭文字のUではなく、本当は「効用（Utility）」の頭文字を表しています。ここで「効用」とか書いちゃうと難しくなるので、「嬉しさ」にしています。↩︎\n ちょっとジャンプがあるかもしれませんが、わからなかった場合はゆっくり考えてみてください。日常的な例（？）でいうと、\\(k\\)が大きいほど、「健康診断のため1ヶ月後に3kg痩せるのは、今すぐに飴玉を1個食べるのと等しいと感じてしまう」ということです。このような人は「今すぐ飴玉2個あげるよ」と言われたら、飴玉2個を食べてしまう（目がくらんでしまう）ということになります。逆に\\(k\\)が小さいと、「1ヶ月後に3kg痩せるのは、今すぐ高級マカロン100個を食べるのと等しいと感じる」ということです。このような人は「今すぐマカロン1個あげるよ」と言われても、「そんな少ないマカロンをもらうぐらいなら、我慢して減量したほうがマシ」と返事をして、拒絶することになるでしょう。↩︎\n ソフトマックス関数といったほうが厳密かもしれません。詳しくは『社会科学のためのベイズ統計モデリング』を読んだり、「ソフトマックス関数　ロジスティック関数」でググったりしてみてください。↩︎\n とりあえずこのコードの意味を意味を理解する必要はないです。↩︎\n 正直、尤度や最尤推定については他にもっと優れた記事があると思うので、わからなければ適宜ググってもらえると嬉しいです。↩︎\n 「積事象」や「尤度」でググってみてください。↩︎\n これをアンダーフローと言います。たとえば、Rのコンソールに1e-1000とか打ってみて、どうなるかを見てみましょう。↩︎\n この説明は端折りますが、一応文系数学の範囲です。「尤度」でググると、この内容は必ず説明されているので、適宜調べてみてください。↩︎\n   ","date":1599264000,"expirydate":-62135596800,"kind":"page","lang":"ja","lastmod":1599264000,"objectID":"7cc1beb657538fa8d5d574ce5b55f3f1","permalink":"https://kirikuroda.github.io/post/2020/09/05/mle-delay-discounting/","publishdate":"2020-09-05T00:00:00Z","relpermalink":"/post/2020/09/05/mle-delay-discounting/","section":"post","summary":"遅延割引課題を例として使います","tags":["実験","データ分析","認知モデル","遅延割引","最尤推定","cognitive modeling","delay discounting","R"],"title":"認知モデルのパラメタを最尤推定する","type":"post"},{"authors":[],"categories":["実験"],"content":"はじめに 想定している読者層 このチュートリアルでは、以下のタイプの読者を想定しています：\n  実験プログラムを書かなきゃいけなくなった心理学（特に社会心理学）系の学部生\n  卒論で（いきなり1）心理学実験のプログラムを書かなくちゃいけなくなった人\n  Pythonの初心者本は一通り読んだけど、いざPsychoPyになるとよくわからない人\n  Coderのどこから手を着ければいいかわからない人\n  せっかくやるならBuilderじゃなくてCoderがいい、でもよくわからない、という人\n  CoderにDemosってやつがあるらしいけど、英語を読むことに苦手意識がある（あるいは、Demosの存在を知らない）という人\n  時間がない人\n  既に公開されている優れたチュートリアル PsychoPyのCoderについては、既に優れたチュートリアルがいくつか公開されています（参照：PsychoPy Coderによる心理学実験作成チュートリアルまとめ）。この「チュートリアルまとめ」、およびそこで紹介されているチュートリアルのいずれにおいても、Pythonの初歩から実験実施までが丁寧に解説されています。\nこのチュートリアルの特色（？） このチュートリアルでは、Pythonの初歩の説明をすっ飛ばします。上で紹介した記事も含め、もっと優れた資料や書籍が山のようにあるからです。\nその代わりに、（社会）心理学の実験で割と使うと思われる機能に絞って話を進めます。くわえてこのチュートリアルでは、最初から完成したコードを見て、それを順に解説していくという方針を取ります。「該当するコードをコピペしていけば、自分の実験も書けるんじゃないか？」と思ってもらえることを狙っています。\n主に説明するのは以下の機能です：\n ダイアログボックス データをCSVに記録 テキスト刺激の呈示 キー押しの検出 クリックの検出 反応時間の計測 マウスやキー押しに応じて刺激の色を変える 反応に応じたフィードバック　etc.  このチュートリアルの試みがどこまでうまくいくかわかりませんが、とりあえずセットアップしてみましょう。\nいきなりやってみるタイプのチュートリアル いきなりセットアップ  この記事ではMacとPsychoPy 2020.2.3を使ってます。この際なので、PsychoPyをアップデートしてください。 https://github.com/kirikuroda/psychopy_coder_demoからファイルをダウンロードして、PCの適当な場所に保存してください。  いきなり実験   先ほどダウンロードしたpsychopy_coder_demo.pyを、PsychoPy Coder（Experiment Runner）で実行してください。\n  すると、短い課題が画面に表示されます。この課題を解説していくので、まずは課題をやってみてください。1分で終わります。\n  （Macで）以下のようなエラーが出る場合は、こちらのページ（英語）を参考にしてください。\nFile “psychtoolbox/hid.pyc”, line 137, in init File “psychtoolbox/hid.pyc”, line 145, in _create_queue FileNotFoundError: [Errno 2] No such file or directory    実験の構造 実験は終わりましたか？　実験の構造を確認しましょう：\n 参加者のIDを入力 教示が表示される Startをクリックすると課題が始まる 最初に試行数が表示される 次に都市名が表示される どちらの都市の人口が多いかをFかJで回答する 何もせずに5秒以上経つと「Hurry up!」が表示される FかJを押すと、選んだ方の都市が黄色くなり、四角で囲まれる 正解不正解のフィードバックが表示される （裏でその試行のデータが記録される） ※4〜10を繰り返す 実験終了のメッセージが表示される  では、コードを順になぞっていきます。\n解説 ダイアログボックスを呈示する（38–46行目） # ダイアログボックスを呈示し、参加者の情報を入力 subj_info = {\u0026quot;subj_id\u0026quot;: \u0026quot;\u0026quot;, \u0026quot;add_here_what_you_want\u0026quot;: \u0026quot;\u0026quot;} dialogue_box = gui.DlgFromDict(subj_info, order = [\u0026quot;subj_id\u0026quot;, \u0026quot;add_here_what_you_want\u0026quot;]) # OKならID（subj_id）を記録して実験を進める。キャンセルなら実験を中止 if dialogue_box.OK: subj_id = subj_info[\u0026quot;subj_id\u0026quot;] else: core.quit()  参加者の情報を入力するためのダイアログボックスを呈示しています。\nadd_here_what_you_wantと書いてあるように、他に記録したい情報がある場合は、後ろに付け足してください。\nデータファイルの名前を作る（52–67行目） # 現在日時を記録 exp_date = data.getDateStr(\u0026quot;%Y%m%d%H%M%S\u0026quot;) # データファイルを保存するフォルダを作る # フォルダがなければ作る try: os.makedirs(\u0026quot;data/csv\u0026quot;) os.makedirs(\u0026quot;data/log\u0026quot;) # フォルダが既にある場合は何もしない except OSError: pass # データファイルの名前を作る（ID_日付） file_name = subj_id + \u0026quot;_\u0026quot; + exp_date file_name_csv = os.path.join(\u0026quot;data/csv/\u0026quot; + file_name + \u0026quot;.csv\u0026quot;) file_name_log = os.path.join(\u0026quot;data/log/\u0026quot; + file_name + \u0026quot;.log\u0026quot;)  参加者のIDと現在日時からファイル名を作っています。プログラムを実行した日時は、何らかの形で記録しておくようにしましょう。\nCSVファイルに行動データ、logファイルに実験のログを記録することにします。\nクイズの項目を読み込む（69–70行目） # クイズの項目（都市名、人口）を読み込む city = pd.read_csv(\u0026quot;city.csv\u0026quot;)  この実験課題で呈示する項目（CSVファイル）を読み込んでいます。\n画面、マウス、キーボードを設定する（76–80行目） # 画面の座標系　units = \u0026quot;norm\u0026quot; # 画面中心が(0, 0)、X軸が-1〜+1、Y軸が-1〜+1 win = visual.Window(width = 1200, height = 900, units = \u0026quot;norm\u0026quot;) mouse = event.Mouse() kb = keyboard.Keyboard()  PsychoPyでは、ふつうスクリーンをwinとして記録します。\n都市名刺激を設定する（86–103行目） # テキスト刺激の色と日本語フォント color_default, color_highlight = \u0026quot;white\u0026quot;, \u0026quot;yellow\u0026quot; font_ja = \u0026quot;ヒラギノ角ゴシック W3\u0026quot; # 刺激（都市名）　textは毎試行変わるので、後で定義 city_1_text = visual.TextStim(win, font = font_ja) city_2_text = visual.TextStim(win, font = font_ja) # 刺激の呈示位置のカウンターバランス # 都市名をX軸方向にどれくらいずらすか city_nudge_x = 0.5 # 4試行のカウンターバランスをcity_posとして保存 city_pos = [\u0026quot;one_two\u0026quot;, \u0026quot;one_two\u0026quot;, \u0026quot;two_one\u0026quot;, \u0026quot;two_one\u0026quot;] # city_text_posを並び替える city_pos = np.random.permutation(city_pos) # 試行の順序をランダマイズする。trial_order: [3, 2, 0, 1]のようになる trial_order = np.random.permutation(range(len(city)))  テキスト刺激はvisual.TextStim()で作ります。日本語フォントは好きなものに修正してもらって構いません。\nここでは、呈示位置のカウンターバランスと、試行順序のランダマイズもしています2。\nキーを設定する（105–112行目） # キー設定 key_left, key_right = \u0026quot;f\u0026quot;, \u0026quot;j\u0026quot; # 押すべきキーの名前（課題中に呈示しておく） # キーのテキストをY軸方向にどれくらいずらすか key_text_nudge_y = 0.5 key_left_text = visual.TextStim(win, text = \u0026quot;F\u0026quot;, pos = (-city_nudge_x, key_text_nudge_y)) key_right_text = visual.TextStim(win, text = \u0026quot;J\u0026quot;, pos = (city_nudge_x, key_text_nudge_y))  Fが左、Jが右に対応するようにしています。\nまた、課題中に呈示する「F」と「J」の刺激もここで作っています。\n教示を定義する（114–121行目） # 教示を定義 inst_text = visual.TextStim(win, alignText = \u0026quot;left\u0026quot;, anchorHoriz = \u0026quot;center\u0026quot;) inst_text.setText(\u0026quot;\u0026quot;\u0026quot; Which city has a larger population? Select the city by pressing the F or J of the keyboard. Click \u0026quot;Start\u0026quot; and work on the task. \u0026quot;\u0026quot;\u0026quot;)  教示を作っています。日本語だと少しめんどくさいので、英語で書いています。\n.setText()を使うと、TextStimにテキストを埋め込むことができます。\nStartボタンを定義する（123–129行目） # ボックスの線の太さ box_line_width = 10 # 開始ボタンのボックスとテキスト start_pos_y = -0.5 # Y軸座標 start_box = visual.Rect(win, width = 0.2, height = 0.2, pos = (0, start_pos_y), lineWidth = box_line_width) start_text = visual.TextStim(win, text = \u0026quot;Start\u0026quot;, pos = (0, start_pos_y))  Startボタンを定義しています。四角形はvisual.Rect()で作ります。\nその他のテキスト刺激や図形を定義する（131–157行目） # 試行間で呈示するテキスト（テキストの中身は毎試行変えるので、後で定義する） iti_text = visual.TextStim(win) # ITIの長さ iti_length = 2 # どちらの都市名を選んだかを何秒呈示するか confirmation_length = 1 # 選んだ方の都市を囲うボックスを定義 city_box_width, city_box_height = 0.5, 0.2 # ボックスのサイズ city_box_left = visual.Rect(win, width = city_box_width, height = city_box_height, pos = (-city_nudge_x, 0), lineColor = color_highlight, lineWidth = box_line_width ) city_box_right = visual.Rect(win, width = city_box_width, height = city_box_height, pos = (city_nudge_x, 0), lineColor = color_highlight, lineWidth = box_line_width ) # 正解不正解のテキスト correct_text = visual.TextStim(win, text = \u0026quot;Correct!\u0026quot;) wrong_text = visual.TextStim(win, text = \u0026quot;Wrong...\u0026quot;) feedback_length = 1 # プロンプトのテキスト hurry_text = visual.TextStim(win, text = \u0026quot;Hurry up!\u0026quot;, pos = (0, 0.8), color = color_highlight) # time_limit秒経過したらプロンプトを出す time_limit = 5  その他のテキスト刺激や図形を定義しています。\nログファイルを設定する（163–164行目） # ログファイルの設定 file_log = logging.LogFile(file_name_log, level = logging.EXP)  ログファイルを設定しています。実験中に何が起きたかをほぼ自動で記録してくれるので、設定しておくことをおすすめします。\n教示を呈示する（170–190行目） # 教示（無限ループ） while True: # Startにカーソルが載ってたら黄色に if start_box.contains(mouse): start_box.setLineColor(color_highlight) start_text.setColor(color_highlight) # 載ってなければ白に else: start_box.setLineColor(color_default) start_text.setColor(color_default) # 教示とボックスを描画 inst_text.draw() start_box.draw() start_text.draw() win.flip() # 開始ボタンがクリックされたら無限ループを抜ける if mouse.isPressedIn(start_box): break  教示を呈示しています。刺激をdraw()してからwin.flip()するのが基本です。\nStartボタンにカーソルが載ったら色を変えるようにしています。これを応用すると、マウスの位置を記録することができます。\nStartボタンがクリックされたらループを抜けます。\nCSVファイルの1行目に変数名を書き込む（192–199行目） # CSVファイルの先頭行に変数名を書き込む with open(file_name_csv, \u0026quot;a\u0026quot;, encoding = \u0026quot;cp932\u0026quot;) as f: writer = csv.writer(f, lineterminator = \u0026quot;\\n\u0026quot;) writer.writerow([ \u0026quot;subj_id\u0026quot;, \u0026quot;trial\u0026quot;, \u0026quot;city_1\u0026quot;, \u0026quot;city_2\u0026quot;, \u0026quot;population_1\u0026quot;, \u0026quot;population_2\u0026quot;, \u0026quot;choice\u0026quot;, \u0026quot;correct_answer\u0026quot;, \u0026quot;result\u0026quot;, \u0026quot;rt\u0026quot;, \u0026quot;key\u0026quot;, \u0026quot;pos\u0026quot; ])  CSVファイルに変数名を書き込んでいます。データを記録するときは、この書き方を真似するのがおすすめです。\nカーソルを消して課題を始める（205–215行目） # カーソルを消す mouse.setVisible(False) # 課題開始 for trial_index in range(len(city)): # 試行間のテキストを定義して描画 iti_text.setText(str(trial_index + 1) + \u0026quot;/\u0026quot; + str(len(city))) iti_text.draw() win.flip() core.wait(iti_length)  カーソルを消してから、試行のループに移っています。\niti_textを定義し、呈示しています。\ncore.wait(秒数)で、プログラムを指定時間止めることができます。\n都市名を呈示（217–244行目） # 刺激テキストをセット city_1 = city[\u0026quot;city_1\u0026quot;][trial_order[trial_index]] city_2 = city[\u0026quot;city_2\u0026quot;][trial_order[trial_index]] city_1_text.setText(city_1) city_2_text.setText(city_2) # ついでに人口と正解も記録しておく population_1 = city[\u0026quot;population_1\u0026quot;][trial_order[trial_index]] population_2 = city[\u0026quot;population_2\u0026quot;][trial_order[trial_index]] if population_1 \u0026gt; population_2: answer = \u0026quot;city_1\u0026quot; else: answer = \u0026quot;city_2\u0026quot; # 刺激の位置のカウンターバランス if city_pos[trial_index] == \u0026quot;one_two\u0026quot;: city_1_text.setPos((-city_nudge_x, 0)) city_2_text.setPos((city_nudge_x, 0)) else: city_1_text.setPos((city_nudge_x, 0)) city_2_text.setPos((-city_nudge_x, 0)) # 刺激を描画 city_1_text.draw() city_2_text.draw() key_left_text.draw() key_right_text.draw() win.flip()  都市名刺激を定義・描画したり、課題に関連するデータを記録したりしています。\n.setPos()を使うと、刺激の呈示位置を変更することができます。\n開始時間を記録し、キーボードをリセット（246–251行目） # 回答を待ち始めた時間をresp_onsetとして記録 resp_onset = core.Clock() # キー押しをリセット kb.getKeys([key_left, key_right], waitRelease = False) kb.clock.reset()  刺激呈示の開始時間を記録し、キーボードをリセットしています。\nここでキーボードをリセットしないと、次の試行にキー押しが引き継がれてしまいます。忘れないようにしましょう。\n回答を待つ（253–318行目） # 回答を待つ（無限ループ） while True: # FかJのキー押しを待つ key_pressed = kb.getKeys(keyList = [key_left, key_right], waitRelease = False) # もしFかJが押されたら if len(key_pressed) \u0026gt; 0: # 反応時間を記録 rt = key_pressed[0].rt # どっちのキーを押したかをkeyとして記録 # カウンターバランスに応じて、どっちの都市を選んだかをchoiceとして記録 if key_pressed[0].name == key_left: key = key_left if city_pos[trial_index] == \u0026quot;one_two\u0026quot;: choice = \u0026quot;city_1\u0026quot; else: choice = \u0026quot;city_2\u0026quot; else: key = key_right if city_pos[trial_index] == \u0026quot;one_two\u0026quot;: choice = \u0026quot;city_2\u0026quot; else: choice = \u0026quot;city_1\u0026quot; # 結果を記録 if choice == answer: result = \u0026quot;correct\u0026quot; else: result = \u0026quot;wrong\u0026quot; # 選んだ方の都市名を黄色にする if choice == \u0026quot;city_1\u0026quot;: city_1_text.setColor(color_highlight) else: city_2_text.setColor(color_highlight) # 選んだ方の都市を囲う四角を描画 if key == key_left: city_box_left.draw() else: city_box_right.draw() # その他の刺激も描画して、1秒間呈示 city_1_text.draw() city_2_text.draw() key_left_text.draw() key_right_text.draw() win.flip() core.wait(confirmation_length) # 刺激の色をリセットし、無限ループから抜ける city_1_text.setColor(color_default) city_2_text.setColor(color_default) break # ※time_limitを過ぎたらプロンプトを出す if resp_onset.getTime() \u0026gt; time_limit: city_1_text.draw() city_2_text.draw() key_left_text.draw() key_right_text.draw() hurry_text.draw() win.flip()  回答を待ちます。反応があったらテキストを黄色にし、四角で囲みます。5秒経過したらプロンプトを出すようにしています。\nコードは長めですが、ここでのキー押し判定や条件分岐は汎用性が高いです。というか、ほとんどの実験はこういう（長い）パーツの組み合わせからできています。\nフィードバックをし、各試行のデータを記録（320–338行目） # 正解不正解のフィードバックを呈示 if result == \u0026quot;correct\u0026quot;: correct_text.draw() else: wrong_text.draw() win.flip() core.wait(feedback_length) # CSVファイルにデータを記録 with open(file_name_csv, \u0026quot;a\u0026quot;, encoding = \u0026quot;cp932\u0026quot;) as f: writer = csv.writer(f, lineterminator = \u0026quot;\\n\u0026quot;) writer.writerow([ subj_id, trial_index, city_1, city_2, population_1, population_2, choice, answer, result, rt, key, city_pos[trial_index] ]) # ログファイルを保存 logging.flush()  正解不正解のフィードバックを出してから、データを記録しています。\nなお、ここでは日本語（都市名）を記録しているので、encoding = \u0026quot;cp932\u0026quot;としていますが、ふつうは要らないです。\n実験終了（344–355行目） # 終わりの画面を定義 finish_text = visual.TextStim(win) finish_text.setText(\u0026quot;\u0026quot;\u0026quot; Finish! Thanks! \u0026quot;\u0026quot;\u0026quot;) # 3秒呈示してから実験終了 finish_text.draw() win.flip() core.wait(3) win.close() core.quit()  終了のメッセージを出して、3秒経過したら実験が終わります。\nおわりに このチュートリアルでは割愛した内容もあります。その中で最も重要なものは「関数の自作」です。関数の自作については、PsychoPy Coderによる心理学実験作成チュートリアルまとめの第7回を読んでください。\nおそらく、このチュートリアルはわかりにくいです。しかし、ここに載っている機能を使えば、大体の社会心理学実験や意思決定実験のたたき台を作ることはできると思います3。かなり駆け足でしたが、このチュートリアルが誰かの役に立てば幸いです。\n  本当は「いきなり」じゃない、すなわち、ある程度想定できたことなんだけど、なかなか準備できないものです。私もそうでした。 \u0026#x21a9;\u0026#xfe0e;\n 試行の順序がシャッフルされているので、本来は呈示位置をシャッフルする必要はないです。一応参考のために書いています。 \u0026#x21a9;\u0026#xfe0e;\n そもそも、この（不親切な）説明に付いて来ようとしている時点でかなりモチベーションがあるはずです。プラスアルファで公式のリファレンスを読めば、実用に耐える実験プログラムをすぐに書けるようになると思います。 \u0026#x21a9;\u0026#xfe0e;\n   ","date":1599004800,"expirydate":-62135596800,"kind":"page","lang":"ja","lastmod":1599004800,"objectID":"c91b412e53eb13fc11668aff2128a3ed","permalink":"https://kirikuroda.github.io/post/2020/09/02/psychopy-coder-tutorial/","publishdate":"2020-09-02T00:00:00Z","relpermalink":"/post/2020/09/02/psychopy-coder-tutorial/","section":"post","summary":"いきなりやってみるタイプのCoderチュートリアル","tags":["実験","プログラミング","Python","PsychoPy"],"title":"PsychoPy Coderチュートリアル","type":"post"},{"authors":[],"categories":["執筆"],"content":"辞書をあらかじめ決めておく タイトルにもあるように、辞書系ツールを紹介します。しかし正直なところ、自分の使いやすいツールなら何でも良いと思います。\n大事なのは、使う辞書をあらかじめ決めておくことです。いざ英語を書くときに、使う辞書が決まっていないと、辞書自体を探すところから始まってしまい、時間やエネルギーが奪われます。あるいは「よくわからないからとりあえずググるかー」となった場合、裏のない情報に運悪くトラップされてしまうかもしれません。使う辞書を先に厳選しておけば、そのような事態は避けられます。\n辞書系ツールを選ぶに当たり、以下の3つを選定基準としています。\n 無料　現状、辞書系ツールに限って言えば、無料で十分だと思います。ただし、専門家じゃないので断言はできません。 オンライン　デバイスの環境に依存しないのがメリットです。ただし当然ですが、ネットにつながらないと使えません。 NO自動翻訳　機械学習による自動翻訳ツールは除きました。なるべく自力で文章を書いたほうが、長期的には自分のスキルアップにつながると思うからです。しかし、自動翻訳ツールが発達している今、こういう考えは時代遅れになりつつあるのかもしれません。  では、辞書系ツールを紹介します。\n英英・類語辞典 LEXICO LEXICO\n語義・類語・例文・語源、オールインワンの辞書サイトです。Oxford Dictionaryによって運営されているようです。アメリカ英語・イギリス英語、両方とも載っているので、英単語の意味を調べるときは、とりあえずこれで良いと思います。\n特に、類語（シソーラス）を調べるときには、必ずこのサイトを使っています。検索窓のメニューを「THESAURUS」にすると、類語を検索できます。あるいは、各単語のページの「+ Synonyms」をクリックしても、類語を見ることができます。\n例文が多いのも魅力的です。各単語のページの「+ More example sentences」をクリックすると、どういうニュアンスで使われることが多いかを確認できます。\nOxford Learner\u0026rsquo;s Dictionaries Oxford Learner\u0026rsquo;s Dictionaries\n名前のとおり、英語学習者用の辞書であるため、LEXICOより情報がコンパクトになっています。単語の意味をさっと確認したいときに便利です。また、平易な英語で語義が説明されているので、LEXICOの説明がわかりにくいときに使うのもおすすめです。頻出単語については、コロケーションや用法も載っています。\nコロケーション Just the Word Just the Word\n単語を検索するとコロケーションが表示される、というシンプルなサイトです。また、気になったコロケーションをクリックすると、例文も表示されます。コロケーションに関するウェブサイト（そういうのをコーパスっていうんでしょうか？）は他にもありますが、Just the Wordは見た目と機能がシンプルであり、使い方がわかりやすいので気に入っています。\nNetspeak Netspeak\nある単語や語順の使用頻度を調べたり、比較したりするのに使います。たとえば、「atとin、どっちがよく使われるんだろう？」とか、「この副詞は文のどこに置かれることが多いんだろう？」と思ったときに使います。\nフレーズ集 Useful Phrases Useful Phrases\n英語論文で頻出のフレーズがまとまっています。\u0026ldquo;English for Writing Research Papers\u0026rdquo;（著・Adrian Wallwork：Springer）という、アカデミック・ライティングの書籍1の付録です。リンク先にある「Free Download: Useful Phrases」をクリックすると、フレーズ集が載ったPDFをダウンロードできます。\n同様のフレーズ集として、Academic Phrasebankというのがあり、結構多くのブログで紹介されています。フレーズの検索性が低いので、私はあまり使っていませんが、有益なサイトの1つだと思います。\nおわりに 以上、「英語を書かなきゃいけないときに使う辞書系ツール」を紹介しました。このようなツールを使うと、Google検索でなんとなく英語を調べるよりは、裏づけのある良質な情報を得られると思います。ぜひ、自分にピッタリのツールを探してみてください。\n  この\u0026quot;English for Writing Research Papers\u0026quot;という本は、非常に参考になりました。昨年、『ネイティブが教える 日本人研究者のための論文の書き方・アクセプト術』（講談社、2019）として翻訳されたので、関心のある人は読んでみてください。 \u0026#x21a9;\u0026#xfe0e;\n   ","date":1598572800,"expirydate":-62135596800,"kind":"page","lang":"ja","lastmod":1598572800,"objectID":"67c2eacf4e33925b1a1cb2211a38fe80","permalink":"https://kirikuroda.github.io/post/2020/08/28/english-dictionary/","publishdate":"2020-08-28T00:00:00Z","relpermalink":"/post/2020/08/28/english-dictionary/","section":"post","summary":"「これ」という辞書を厳選するのが大事","tags":["執筆","論文","アカデミックライティング","アカデミックイングリッシュ","辞書","ライティング"],"title":"英語を書かなきゃいけないときに使う辞書系ツール","type":"post"},{"authors":[],"categories":["生活"],"content":"はじめに 10万円が給付されたので、改めて身の回りのものを買い揃えました。買ってよかったものを8つ紹介します。\niPhone SE（第2世代） iPhone SE（第2世代）\n高校の頃から10年近く使ってきたガラケーにガタが来ていました。これまではiPod touchやiPadでごまかしてきたけれど、ようやく腹をくくってiPhoneを買うことにしました。おおむね便利です。\nしかし、iPhoneを導入してから数日後、外出先で通知を確認するのがめちゃくちゃめんどくさい、というか、通知を見逃しやすいということに気がつきました。ガラケーと違い、通知のバイブレーションが短くて弱すぎたのです。\nこの「通知気づきにくい問題」に対処するため、Apple Watchを買いました。\nApple Watch Series 3 Apple Watch Series 3\n買う当初は「スマートウォッチって贅沢すぎでは？」と思っていましが、使っているうちに、この1年でベスト3くらいの買い物だと考えを改めることになりました。以下の3つが特に便利です。\n  必ず通知に気づく：当初の計画通り、通知を見逃さずに済むようになりました。また、必ず通知に気づくようになったことで、メールやメッセージアプリを確認する回数、すなわち、無駄にデバイスを見る時間が減りました。これは時間の節約になるし、精神的な疲労の軽減にもつながると思います。Twitter等のSNSをやっている人だと、この時短効果はより大きいのではないでしょうか。\n  支払いが楽：Apple WatchにモバイルSuicaを入れておけば、レジの読み取り機や自動改札機にタッチするだけで決済できるようになります。スマホだけでもキャッシュレス決済はできるけれど、いちいちスマホを取り出さずに済むのは予想以上に楽です。\n  ライフログを取れる：これは贅沢かもしれないですが、なんとなくライフログを取ることにしました。Autosleep（自動で睡眠時間を記録してくれるアプリ）とLife Cycle（いつ、どこら辺にいたかを記録してくれるアプリ）を使っています。よく運動をする人であれば、この他にも活用法を見いだせると思います。\n  逆に、スマートウォッチを持っていない人は、どうやって通知を確認しているのでしょうか？　いちいちスマホを開くのが無駄だと感じている場合は、購入を考えても良いかもしれません。\nBellroyのスマホケース Phone Case – 3 Card\n名前の通り、背面にカードを3枚入れられるスマホケースです。このケースの中に、クレジットカード・学生証・大学生協の組合員証を入れています。これのおかげで財布をほぼ使わなくなったし、近場に行くときには財布を持つことすらなくなりました。\nこのスマホケースは10000円します。カードを入れられるスマホケースで、もっと安いものはいくらでも見つかると思います。実際、私も「さすがに贅沢では」と悩みましたが、ふだん安物買いの銭失いで失敗することが多いので、思い切って買うことにしました。長く使いたいです。\nAirPods Pro AirPods Pro\nめちゃくちゃ良いです。ノイズキャンセリング性能が良いのはもちろんのこと、装着感が軽いのが何より素晴らしいです。自分は音楽をほぼ聞かないし、かなりいい値段もするけれど、それでも買って良かったと思います。\nクリアサングラス 日差しがまぶしすぎるので、例年、夏になるとサングラスをかけています。しかし、今年はマスクを着けなければいけないので、サングラスをかけると不審者に見えてしまうという問題が生じました。\nそこで、クリアサングラス（透明なサングラス）を買いました。見た目にはふつうの眼鏡なので、マスクと合わせても不審者感は全くないです。地味にいい買い物でした。\nTHERMOSの真空断熱タンブラー 真空断熱タンブラー\n真空断熱タンブラーこそ、「地味に生活のクオリティを上げてくれるアイテム」の筆頭だと思います。これまで2年くらい、サーモスのステンレス製タンブラーを使ってきました。今回買い替えたのは、（おそらく）経年劣化のために保冷効果が弱まってきたからです。\n今までのステンレス製とは違い、今回買ったのは陶器っぽいマットな仕上がりで、飲み口も柔らかくなっています。他にも色や素材にバリエーションがあるので、気になった方は調べてみてください。\n洗顔ネット 持っている人からしたら当たり前のことですが、洗顔ネットを使うと「どこにこんな泡があったんだ！？」というレベルでもこもこ泡立ちます。はじめて使ったとき、この数ヶ月で一番びっくりしました。値段も全然高くないし、一度買えば数年から一生は使えると思うので、買ってよかったです。\nREALFORCEのキーボード REALFORCE TKL SA for Mac\nREALFORCEというのは、有名なキーボードブランドの1つです。HHKBというブランドもありますが、個人的には、REALFORCEのほうが軽くて好みです。\nそれなりに文章に接する職業の人間、すなわち博士課程の院生なら、高めのキーボードを買ったほうが良いと思います。ふつうのキーボードより手への負担が減るだけでなく、文章を書くこと自体がなんとなく楽しくなります。\nちなみに、同じメーカーでもキーボードの種類が多いので、買うときは公式サイトやネットの情報をよく調べるようにしてください。\nおわりに どのアイテムもそれなりに贅沢ですが、地味に、でも確実に生活のクオリティを上げてくれます。いいものを買ってるので、それに見合った仕事をしたいです。\n","date":1598313600,"expirydate":-62135596800,"kind":"page","lang":"ja","lastmod":1598313600,"objectID":"361563e4ae71546fe1469758d654412d","permalink":"https://kirikuroda.github.io/post/2020/08/25/mustbuy-2020-summer/","publishdate":"2020-08-25T00:00:00Z","relpermalink":"/post/2020/08/25/mustbuy-2020-summer/","section":"post","summary":"どのアイテムも地味に生活のクオリティを上げてくれます","tags":["買ってよかったもの","生活"],"title":"大学院生が（いまさら）買ってよかったもの8選","type":"post"},{"authors":[],"categories":["プレゼンテーション"],"content":"数年前のことですが、データ可視化・報告・ggplot2の初歩をまとめました。こちらで読むことができます。\n","date":1598054400,"expirydate":-62135596800,"kind":"page","lang":"ja","lastmod":1598054400,"objectID":"0e71f22d516f818d4b304bf3288f0715","permalink":"https://kirikuroda.github.io/post/2020/08/22/datareporting/","publishdate":"2020-08-22T00:00:00Z","relpermalink":"/post/2020/08/22/datareporting/","section":"post","summary":"ggplot2の基礎","tags":["プレゼンテーション","データビジュアライゼーション","ggplot2","R","可視化"],"title":"データの可視化 まとめ","type":"post"},{"authors":[],"categories":["執筆"],"content":"2年ぶりにウェブサイトをリニューアルしました。リニューアルにあたり、かねがね気になっていたHugo Academicというテンプレートと、blogdown（Rのパッケージ）を使うことにしました。\nサイト構築の詳しい手順は説明しませんが、1日から2日で一通り作ることができました。もう少し時間をかければ、配色やフォントを自分好みにカスタマイズできそうです。\nそこまで労せずして、自分にしてはオシャレ（？）なサイトを作ることができて良かったです。くわえて、Markdown / R Markdownで記事を書くことができるのも嬉しいポイントです。気が向いたらなにか書きたいです。\n","date":1597968000,"expirydate":-62135596800,"kind":"page","lang":"ja","lastmod":1597968000,"objectID":"2a8bcafec0a63ad9da8c1ad9640c9419","permalink":"https://kirikuroda.github.io/post/2020/08/21/hugo-academic/","publishdate":"2020-08-21T00:00:00Z","relpermalink":"/post/2020/08/21/hugo-academic/","section":"post","summary":"Hugo Academicとblogdownがおすすめ","tags":["Hugo Academic","R","blogdown","Wowchemy","執筆","ブログ"],"title":"Hugo Academicでウェブサイトをリニューアルしました","type":"post"},{"authors":["Kiri Kuroda","Yoshio Kamijo","Tatsuya Kameda"],"categories":null,"content":"","date":1586908800,"expirydate":-62135596800,"kind":"page","lang":"ja","lastmod":1586908800,"objectID":"db1dbbf5b1bea1a434ccd9a4f382a2ea","permalink":"https://kirikuroda.github.io/publication/kuroda2020investor/","publishdate":"2020-04-15T00:00:00Z","relpermalink":"/publication/kuroda2020investor/","section":"publication","summary":"Trust is a vital element of any society. Previous studies using trust games have provided insight into understandings of trusting behavior. However, investors' behaviors can be confounded by their risk preferences in the game, and little is known about the relationship between stake size and beliefs of others' good intentions underlying trust. We thus used a variant of the trust game and conducted two experiments to examine how stake size affects investors' beliefs about receivers' trustworthiness, with model‐based analyses. We showed that, when holding all else equal, investors trusted more, but their expectations of reciprocation declined as stake size increased. However, actual receivers' reciprocation rates showed the opposite trend to investors' pessimistic beliefs. Furthermore, following previous studies in social psychology, we hypothesized that investors' social preferences (social value orientation) moderated the beliefs underlying trust, but they had no explanatory powers in investors' expectations of reciprocation. These results suggest that peoples' naive beliefs about stake size play a more important role in trust decisions than expected.","tags":null,"title":"Investor's Pessimistic and False Belief About Trustworthiness and Stake Size in Trust Decision","type":"publication"},{"authors":["Kiri Kuroda","Tatsuya Kameda"],"categories":null,"content":"","date":1567296000,"expirydate":-62135596800,"kind":"page","lang":"ja","lastmod":1567296000,"objectID":"a397c82ab5310cf19f8ff5a2efed513a","permalink":"https://kirikuroda.github.io/publication/kuroda2019you/","publishdate":"2019-09-01T00:00:00Z","relpermalink":"/publication/kuroda2019you/","section":"publication","summary":"Predation risk is a significant concern when social animals including humans engage in foraging. When people search for resources together, individuals often find themselves in a producer–scrounger game, in which some individuals bear the cost of risk monitoring while others can free ride on those efforts. A theoretically rational strategy is to mix foraging and risk monitoring randomly with the same probability across all members, but such uncoordinated action often yields inefficiencies of under- or over-supply of risk monitoring in a group. Here, we examined whether people could spontaneously develop a coordinated risk-monitoring system, alternating vigilance and foraging in a pair. Given that human cooperation is vulnerable to fear of exploitation and emotional arousal under risk, we hypothesized that such sources of anxiety would be potential disruptors to coordination. In a laboratory experiment, two participants worked on a “treasure hunt” task simultaneously, in which they chose between low or high vigilance against predators during foraging without verbal communication. If one chose high vigilance with personal cost, it yielded a spillover benefit to the other. Besides behavioral choices, each participant's physiological arousal (skin conductance response) and cognitive effort (tonic pupil dilation) were measured during the task. Results showed that some pairs were actually able to develop a role-alternating system over time through tacit coordination, but coordinated action was also vulnerable to anxiety and mistrust among participants. Overall, these results imply that, besides the mutual behavioral control that often characterizes repeated interaction, cognitive control of emotional arousal may be a critical psychological factor for the emergence of coordinated cooperation.","tags":null,"title":"You Watch My Back, I'll Watch Yours: Emergence of Collective Risk Monitoring Through Tacit Coordination in Human Social Foraging","type":"publication"},{"authors":["Gregory A. Bryant","Daniel M. T. Fessler","Riccardo Fusaroli","Edward Clint","Dorsa Amir","Brenda Chávez","Kaleda K. Denton","Cinthya Díaz","Lealaiauloto Togiaso Duran","Jana Fanćovićová","Michal Fux","Erni Farida Ginting","Youssef Hasan","Anning Hu","Shanmukh V. Kamble","Tatsuya Kameda","Kiri Kuroda","Norman P. Li","Francesca R. Luberti","Raha Peyravi","Pavol Prokop","Katinka J. P. Quintelier","Hyun Jung Shin","Stefan Stieger","Lawrence S. Sugiyama","Ellis A. van den Hende","Hugo Viciana-Asensio","Saliha Elif Yildizhan","Jose C. Yong","Tessa Yuditha","Yi Zhou"],"categories":null,"content":"","date":1532476800,"expirydate":-62135596800,"kind":"page","lang":"ja","lastmod":1532476800,"objectID":"34399f7cf276aada85e50a0ae1bc4df3","permalink":"https://kirikuroda.github.io/publication/bryant2018perception/","publishdate":"2018-07-25T00:00:00Z","relpermalink":"/publication/bryant2018perception/","section":"publication","summary":"Laughter is a nonverbal vocalization occurring in every known culture, ubiquitous across all forms of human social interaction. Here, we examined whether listeners around the world, irrespective of their own native language and culture, can distinguish between spontaneous laughter and volitional laughter—laugh types likely generated by different vocal-production systems. Using a set of 36 recorded laughs produced by female English speakers in tests involving 884 participants from 21 societies across six regions of the world, we asked listeners to determine whether each laugh was real or fake, and listeners differentiated between the two laugh types with an accuracy of 56% to 69%. Acoustic analysis revealed that sound features associated with arousal in vocal production predicted listeners’ judgments fairly uniformly across societies. These results demonstrate high consistency across cultures in laughter judgments, underscoring the potential importance of nonverbal vocal communicative phenomena in human affiliation and cooperation.","tags":null,"title":"The Perception of Spontaneous and Volitional Laughter Across 21 Societies","type":"publication"}]